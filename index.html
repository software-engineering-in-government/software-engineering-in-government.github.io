<!DOCTYPE html>
<html lang="en">
  <head>
   <meta charset='utf-8'>
   <meta name='generator' content='Pluto 1.5.6 on Ruby 2.7.0 (2019-12-25) [x86_64-linux]'>
   <title>Government Software Engineering Community Blog</title>

   <link rel='stylesheet' type='text/css' href='css/digest.css'>
   <link href="atom.xml" type="application/atom+xml" rel="alternate" title="Atom feed" />
  </head>
  <body>
    <div class='container'>
      <header class='masthead'>
        <h1>Government Software Engineering Community Blog</h1>
        <p>Blog posts from the UK government software development community</p>
        <p><a href="atom.xml"><img width="30" src="images/rss.svg" alt="Atom Feed"></a></p>
      </header>


      <!-- 1) list headlines w/ inline links -->
      <nav class='contents'>
        <p><b>Contents</b></p>
        <ol>

        
          <li>
              <a href='#post-1'>Moving towards Continuous Delivery</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  28 days ago
              </span>
          </li>
        
          <li>
              <a href='#post-2'>Our next cross-government API event on 13 November with DWP</a>
              <span class='item-feed-title'>
                &bull; <a href='https://technology.blog.gov.uk/category/open-standards/'>Technology in government</a>
              </span>
              <span class='item-published'>
                &bull;  3 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-3'>Add your API to the cross-government catalogue</a>
              <span class='item-feed-title'>
                &bull; <a href='https://technology.blog.gov.uk/category/open-standards/'>Technology in government</a>
              </span>
              <span class='item-published'>
                &bull;  4 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-4'>Improve CSVs and API descriptions with these Open Standards Board recommendations</a>
              <span class='item-feed-title'>
                &bull; <a href='https://technology.blog.gov.uk/category/open-standards/'>Technology in government</a>
              </span>
              <span class='item-published'>
                &bull;  4 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-5'>Bringing Disparate Data Sources Under Control with Good Metadata</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  5 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-6'>Organising Variables in Terraform</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  6 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-7'>When worlds collide: putting data science into production</a>
              <span class='item-feed-title'>
                &bull; <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>
              </span>
              <span class='item-published'>
                &bull;  6 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-8'>How to use multi-stage Docker builds</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  7 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-9'>Working Days Calculator</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  7 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-10'>A or B? How we test algorithms on GOV.UK</a>
              <span class='item-feed-title'>
                &bull; <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>
              </span>
              <span class='item-published'>
                &bull;  8 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-11'>Natural Language Processing in government</a>
              <span class='item-feed-title'>
                &bull; <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>
              </span>
              <span class='item-published'>
                &bull;  8 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-12'>Reducing cost and latency of change for legacy services</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  8 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-13'>Automated Unit Testing of PL/SQL</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  8 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-14'>Measuring against cyber security standards</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  8 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-15'>When making a private GitHub repository public, audit the pull requests</a>
              <span class='item-feed-title'>
                &bull; <a href='https://medium.com/just-tech'>Just Tech</a>
              </span>
              <span class='item-published'>
                &bull;  9 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-16'>Connecting the dots: network science on GOV.UK</a>
              <span class='item-feed-title'>
                &bull; <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>
              </span>
              <span class='item-published'>
                &bull;  9 months ago
              </span>
          </li>
        
          <li>
              <a href='#post-17'>Detecting semantic similarity on GOV.UK</a>
              <span class='item-feed-title'>
                &bull; <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>
              </span>
              <span class='item-published'>
                &bull;  9 months ago
              </span>
          </li>
        <!-- each item -->
        </ol>
      </nav>

      <main>
      <!-- 2) list full articles -->

      
        <article id="post-1" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 1.  -->
              <a href='https://medium.com/just-tech/moving-towards-continuous-delivery-8200131350fa?source=rss----71364e71d6c2---4'>Moving towards Continuous Delivery</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Tuesday January 14, 2020 @ 08:53 &bull;
              28 days ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Bethan Palmer and Mat Moore (Software Development Profession)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*QcjI9ASxo9cvQ6HgEOtZYA.jpeg" /></figure><p>In LAA digital, we are moving towards Continuous Delivery as part of modernising CCMS (Client and Cost Management System). CCMS is one of several <a href="https://mojdigital.blog.gov.uk/2018/11/22/announcing-the-application-modernisation-team1/">legacy services we are modernising in the MOJ</a>. So far we have been focusing mainly on one part of CCMS, the Provider User Interface.</p><blockquote>Continuous Delivery is the ability to get changes of all types — including new features, configuration changes, bug fixes and experiments — into production, or into the hands of users, <em>safely</em> and <em>quickly</em> in a <em>sustainable</em> way. <a href="https://continuousdelivery.com/">https://continuousdelivery.com/</a></blockquote><p>Historically, the deployment process for CCMS has involved a lot of steps, and a lot of different people need to be involved throughout the process to get a change from development to production.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*2r-rXfkc_EsYi_hr" /></figure><p>When a release process is complex and time consuming, releases happen infrequently. Because they happen infrequently they are risky as they contain a lot of changes. And because they are risky they tend to happen even less often. So there becomes a cycle of infrequent releases which is difficult to break out of. We wanted to avoid this situation by moving towards frequent deployments to production.</p><h3>Things that we want to change</h3><p>The bottlenecks in the deployment process were:</p><ul><li>Deployments needed to be planned, and required approval from various people to proceed</li><li>We needed to do a lot of manual testing, and our case workers or the live support team also manually smoke tested each deployment to make sure we hadn’t broken anything</li><li>We needed to run separate builds for each environment we deploy to, instead of building a single artefact and deploying it to each environment in turn</li><li>We had to develop the code in a shared development environment, which was firewalled off from the internet and difficult to work on</li></ul><p>We are working to remove these bottlenecks so that we can deploy to production quickly and easily. Our end goal is to promote changes from the development environment through to production in less than 15 minutes.</p><h3>What we’ve done so far</h3><p>Below are some of the changes we’ve made which are helping us move towards Continuous Delivery.</p><h4>Updated the unit tests</h4><p>There were already some existing unit tests, but several of them contained hardcoded paths to configuration files we didn’t have access to. We re-wrote some of these tests, removed some of them, and wrote some new unit tests to increase our test coverage.</p><h4>Added CircleCI (continuous integration)</h4><p>We added an integration with CircleCI, which runs our unit tests every time we create a Pull Request in GitHub. It also checks our code’s dependencies for security vulnerabilities every night. Eventually we want to automate deployments from here too.</p><h4>Written some end to end tests</h4><p>We’ve written some browser tests that automate someone clicking through the application. Running these gives us confidence that our changes haven’t broken any of the basic functionality.</p><h4>Improved the application build process</h4><p>We have replaced the old Ant build with a new Gradle build. Ant and Gradle are both build automation tools for Java applications, but Gradle has several advantages over Ant. For example with Gradle we are able to delete checked in dependencies and use remote ones, making it much easier to upgrade them. Gradle is a simpler tool for developers to use and the build process is quicker, which makes developing code changes easier.</p><h4>Created a Docker/Tomcat build we can run locally</h4><p>We are now able to build the application and deploy it to Tomcat running in a Docker container. This means we can develop and test our changes locally instead of relying on the shared development environment, which is very difficult to use. This gives us a much quicker feedback loop when doing development work.</p><h4>Spiked out what our ideal deployment pipeline into AWS might look like</h4><p>We did a <a href="https://github.com/ministryofjustice/deployment-pipeline-hello-world">spike to demonstrate how our end goal might work with a simple Hello World application</a>. This involved creating a pipeline in CircleCI that builds the app, tests it, and deploys it to multiple environments in AWS with zero downtime. We also want to look at spinning up ephemeral environments that get deleted after a certain amount of time. Another department in the MoJ, the Office of the Public Guardian, had already created a similar deployment pipeline so we were able to use their work as a guideline for ours.</p><h3>Next steps</h3><h4>Migrate to AWS</h4><p>CCMS could not be included in <a href="https://medium.com/just-tech/reducing-cost-and-latency-of-change-for-legacy-services-5ab85a0f339f">our previous migration to AWS</a>. Now that we have a better understanding of the process, we intend to repeat the same steps to move CCMS out of the current data centre and deploy into public cloud. This will reduce the cost of running the service, but will also allow us to run fully automated deployments. This enables us to make changes more quickly and safely.</p><h4>Increase our test coverage</h4><p>Our test coverage is still very low (6% for the Provider User Interface). We want to increase this so that we have less reliance on manual testing, and can be confident we are releasing changes safely.</p><h4>Adopt Continuous Deployment</h4><p>When we have achieved Continuous Delivery, the next step is to move to Continuous Deployment (where the release is automated from CircleCI rather than a manual process, and there is zero downtime).</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital?source=post_page---------------------------">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/?source=post_page---------------------------">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/?source=post_page---------------------------">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology?source=post_page---------------------------"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8200131350fa" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/moving-towards-continuous-delivery-8200131350fa">Moving towards Continuous Delivery</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-2" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 2.  -->
              <a href='https://technology.blog.gov.uk/2019/11/05/our-next-cross-government-api-event-on-13-november-with-dwp/'>Our next cross-government API event on 13 November with DWP</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://technology.blog.gov.uk/category/open-standards/'>Technology in government</a>  &bull;
            </span>
            <span class='item-published'>
              Tuesday November 05, 2019 @ 09:57 &bull;
              3 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p><img class="aligncenter wp-image-4003" src="https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/06/47804251311_d7dcaa5213_k-1-300x200.jpg" alt="Group discussion during API event" width="613" height="409" srcset="https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/06/47804251311_d7dcaa5213_k-1-300x200.jpg 300w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/06/47804251311_d7dcaa5213_k-1-768x512.jpg 768w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/06/47804251311_d7dcaa5213_k-1-1024x683.jpg 1024w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/06/47804251311_d7dcaa5213_k-1-435x290.jpg 435w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/06/47804251311_d7dcaa5213_k-1.jpg 2048w" sizes="(max-width: 613px) 100vw, 613px" /></p>
<p><span style="font-weight: 400">The agenda is now </span><a href="https://www.eventbrite.co.uk/e/api-community-meet-up-newcastle-tickets-74084931023"><span style="font-weight: 400">live on our Eventbrite page</span></a><span style="font-weight: 400"> and contains a good selection of technical and strategic talks, as well as some case studies and a panel discussion. </span></p>
<h2><b>API reuse discussions on the agenda </b></h2>
<p><span style="font-weight: 400">I’m particularly looking forward to the discussions on API reuse. When </span><a href="https://technology.blog.gov.uk/2019/10/11/add-your-api-to-the-cross-government-catalogue/"><span style="font-weight: 400">launching the government API catalogue</span></a><span style="font-weight: 400"> a few weeks ago, we cited one of its core objectives as helping improve transparency of API development across government. That it has done, with even the few APIs that have been added already. </span></p>
<p><span style="font-weight: 400">What the catalogue could also potentially do is get API development teams thinking about how components they design can be reused across government. </span></p>
<p><span style="font-weight: 400">But the question is how much is API reuse even possible, and what are we talking about when discussing reuse? API reuse could refer to:</span></p>
<ul>
<li style="font-weight: 400"><span style="font-weight: 400">API processes, like how clients do testing </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">API functionality, like the access rights and security policies implemented, or the documentation template used </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">the data sets the APIs call</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">the whole API, like is the case with <a href="https://www.payments.service.gov.uk/">GOV.UK Pay</a> and <a href="https://www.notifications.service.gov.uk/">GOV.UK Notify</a>, which are both treated as products each time they are deployed by a government organisation</span></li>
</ul>
<p><span style="font-weight: 400">At the meetup, we’ll be hearing from DWP and HMRC on what kind of API reuse they think is possible, and what API development teams should be thinking about when developing an API with reuse in mind. </span></p>
<h2><b>Suppliers welcome at this meetup</b></h2>
<p><span style="font-weight: 400">We’ve held quite a few API meetups in recent years but this is the first time we’ve given suppliers a voice in the agenda and really tried to make them feel welcome. </span></p>
<p><span style="font-weight: 400">It’s important we involve suppliers working on APIs in the public sector so we can </span><span style="font-weight: 400">learn from suppliers’ cross-government views and approaches as they implement similar APIs in many different departments. This will also </span><span style="font-weight: 400">ensure suppliers follow the same thinking and best practices as the rest of the cross-government API and data exchange community. </span></p>
<p>We'll also <span style="font-weight: 400">hear from more niche suppliers in areas such as API management on what they think the future will hold for tooling - we’ll be holding a panel at the event on the future of API management to try to get some thoughts in this particular area.</span></p>
<h2><b>A good mix of technical and strategic talks </b></h2>
<p><span style="font-weight: 400">The API meetups we’ve been holding for the last couple of years have been slowly changing from more technical discussions (as we tried to nail down the </span><a href="https://www.gov.uk/guidance/gds-api-technical-and-data-standards"><span style="font-weight: 400">Government API standards</span></a><span style="font-weight: 400"> and the </span><a href="https://www.gov.uk/government/collections/api-design-guidance"><span style="font-weight: 400">accompanying guidance</span></a><span style="font-weight: 400">) to more strategic discussions (as more departments are launching full API strategies). </span></p>
<p><span style="font-weight: 400">At this event, we’ve tried to ensure a mix of both technical and strategic talks so the event can appeal to all of those in the API community, from the technical architects and the rest of the API design team, to those in senior management setting the API strategies. </span></p>
<p><span style="font-weight: 400">This meetup will focus on some more technical and practical areas, like how we, </span><span style="font-weight: 400">best support clients to test our APIs, </span><span style="font-weight: 400">think about designing data APIs and </span><span style="font-weight: 400">do user research for APIs.</span></p>
<p><span style="font-weight: 400">We’ll then be moving on to some strategic discussions, like how </span><span style="font-weight: 400">the Ministry of Defence (MOD) is moving to an API First organisation. We'll also hear how </span><span style="font-weight: 400">the Italian government is working with the API international standards community and how </span><span style="font-weight: 400">Newcastle is using APIs as an asset. </span><span style="font-weight: 400">DWP will present on how it's using APIs to transform its organisation.</span></p>
<h2><b>Join the Government API and data exchange community</b></h2>
<p><span style="font-weight: 400">Our event on 13 November is unfortunately already sold out but please </span><a href="mailto:api-data-request@digital.cabinet-office.gov.uk"><span style="font-weight: 400">email us if you would like to join</span></a><span style="font-weight: 400"> the waiting list for the event and </span><span style="font-weight: 400">the Government API and data exchange community. Being part of the community means you will be kept updated on more events like this. </span></p>
<p><span style="font-weight: 400">The full agenda of the event is below. </span></p>
<h2><b>Agenda</b></h2>
<p><span style="font-weight: 400">09:30am to 10am: </span>Coffee and networking</p>
<p><span style="font-weight: 400">10am to 10:10am: </span>Welcome<span style="font-weight: 400">, Rosalie Marshall, Government Digital Service (GDS)</span></p>
<p><span style="font-weight: 400">10:10am to 10:30am : </span>4 ways we’re improving API and data exchange capability<span style="font-weight: 400">, Rosalie Marshall (GDS)</span></p>
<p><span style="font-weight: 400">An update from GDS on the launch of the API catalogue, new guidance on API management and API principles, the data standards work and the updated API standards.</span></p>
<p><span style="font-weight: 400">10:30am to 10:50am: </span>API user research for COGS<span style="font-weight: 400">, Alex Tucker and Bill Roberts (Office for National Statistics and Swirrl)</span></p>
<p><span style="font-weight: 400">Where we are with API user research and design for the Connected Open Government Statistics project with ONS.</span></p>
<p><span style="font-weight: 400">10:50am to 11am: </span>API Reuse: how straightforward is it?<span style="font-weight: 400"> Richard Baines (HMRC)</span></p>
<p><span style="font-weight: 400">The ability to reuse APIs is often cited as a potential benefit to creating them, but is it as clear cut as it seems? Some lessons from HMRC’s experience in implementing its API strategy.</span></p>
<p><span style="font-weight: 400">11am to 11:25am: </span>The Benefits API: a case study on cross-government working<span style="font-weight: 400">, Jacqui Leggetter (DWP)</span></p>
<p><span style="font-weight: 400">A talk from DWP on the Benefits API between DWP and NHS, covering its reusable components and its benefits to the Blue Badge Scheme.</span></p>
<p><span style="font-weight: 400">11:25am to 11:40am: </span>An Ofgem API case study<b>, </b><span style="font-weight: 400">Deborah Fehindemi (Ofgem) and Valtech speaker TBC.</span></p>
<p><span style="font-weight: 400">11:40am to 12pm: </span>Supporting API clients<span style="font-weight: 400">, David Heath (GOV.UK Pay)</span></p>
<p><span style="font-weight: 400">A talk from GOV.UK Pay on how to support the development process of clients using your API.</span></p>
<p><span style="font-weight: 400">12pm to 12:20pm: </span>Designing data APIs<span style="font-weight: 400">, Simon Worthington and Andy Bennet (</span><span style="font-weight: 400">Register Dynamics) </span></p>
<p><span style="font-weight: 400">How data APIs are different from transactional APIs and how to best design them to make it easy to keep data up-to-date.</span></p>
<p>12:20pm to 1pm: Buffet lunch &amp; networking (hosted by DWP)</p>
<p><span style="font-weight: 400">1pm to 1:20pm: </span>How we as a city can push APIs as a city asset<span style="font-weight: 400">, Dr Luke Smith (Newcastle University’s Urban Observatory)</span></p>
<p><span style="font-weight: 400">1:20pm to 1:40pm: NHS (TBC), Jonathon Telfer and Mark Chapman</span></p>
<p><span style="font-weight: 400">1:40pm to 2:00pm: </span>Moving the MOD to an API-first organisation<span style="font-weight: 400">, Richard Williams and John Wharton (MOD)</span></p>
<p><span style="font-weight: 400">2:00pm to 2:15pm: Break</span></p>
<p><span style="font-weight: 400">2:15pm to 2:20pm: Video - h</span>ow we work with API international standards to drive consistency,<span style="font-weight: 400"> Roberto Polli (Italian Government)</span></p>
<p><span style="font-weight: 400">2:20pm to 2:35pm: </span>Using APIs to help drive business transformation, <span style="font-weight: 400">Andy Penrose (DWP)</span></p>
<p><span style="font-weight: 400">A talk from DWP on how they are using APIs to transform their organisation and remove some of their operational silos. This will also cover API enablement and the 6 key things DWP have identified that make an organisation API ready.</span></p>
<p><span style="font-weight: 400">2:35pm to 2:55pm: </span>Panel - the future of API Management</p>
<p><span style="font-weight: 400">Panellists: HMRC, DWP, NHS, Mulesoft, WS02</span></p>
<p><span style="font-weight: 400">2:55pm to 3:00pm: </span>Close<span style="font-weight: 400">, Rosalie Marshall</span></p>
            
            </div>
          </div>
        </article>
      
        <article id="post-3" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 3.  -->
              <a href='https://technology.blog.gov.uk/2019/10/11/add-your-api-to-the-cross-government-catalogue/'>Add your API to the cross-government catalogue</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://technology.blog.gov.uk/category/open-standards/'>Technology in government</a>  &bull;
            </span>
            <span class='item-published'>
              Friday October 11, 2019 @ 09:51 &bull;
              4 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p><img class="aligncenter wp-image-4288 size-full" src="https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/10/API-catalogue2.jpg" alt="" width="613" height="311" srcset="https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/10/API-catalogue2.jpg 613w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/10/API-catalogue2-300x152.jpg 300w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2019/10/API-catalogue2-435x221.jpg 435w" sizes="(max-width: 613px) 100vw, 613px" /></p>
<p><span style="font-weight: 400">We’re inviting government organisations (both local and central) to post details of their APIs on GitHub so we can improve the picture we have of development taking place across government and the types of data sharing occurring. </span></p>
<h2><span style="font-weight: 400"><strong>Why we need more transparency and consistency in the API space</strong> </span></h2>
<p><span style="font-weight: 400">Even though there’s more cross-government working in the API space than ever before, there are still many cases of government organisations developing APIs in isolation. This can lead to the government solving the same problem multiple times, often in different ways. </span></p>
<p><span style="font-weight: 400">GDS, along with the API and Data Exchange cross-government community, maintains a set of </span><a href="https://www.gov.uk/guidance/gds-api-technical-and-data-standards"><span style="font-weight: 400">API Standards</span></a><span style="font-weight: 400"> and </span><a href="https://www.gov.uk/government/collections/api-design-guidance"><span style="font-weight: 400">API design guidance</span></a><span style="font-weight: 400">, and holds regular API events, all in order to agree common standards and the sharing of best practice. Collaborating on a list of APIs should create more transparency in the development space, and should further help government </span><span style="font-weight: 400">development teams communicate with each other about challenges and approaches. </span></p>
<p><span style="font-weight: 400">Publishing an open list of government APIs is an approach increasingly common internationally. At a </span><a href="https://technology.blog.gov.uk/2019/05/22/10-things-we-learned-from-our-api-community-of-practice-event/"><span style="font-weight: 400">recent API event</span></a><span style="font-weight: 400">, Canada’s </span><span style="font-weight: 400">Office of the Chief Information Officer presented on its cross-government </span><a href="https://api.canada.ca/en/homepage"><span style="font-weight: 400">API Store</span></a><span style="font-weight: 400">. </span></p>
<p><span style="font-weight: 400">The Canadian API Store is a catalogue of government APIs to increase findability, and is a collaborative effort across government. Users can discover services or data through the API Store to help the Canadian government’s ‘</span><a href="https://www.canada.ca/en/revenue-agency/news/2018/02/the_government_ofcanadaislaunchingatellusonceapproachforonlinedi.html"><span style="font-weight: 400">tell us once'</span></a><span style="font-weight: 400"> pro</span><span style="font-weight: 400">gramme of work.</span></p>
<p><span style="font-weight: 400">Other governments running similar projec</span><span style="font-weight: 400">ts include the </span><a href="https://github.com/18F/api.data.gov/blob/master/data/apis.yml"><span style="font-weight: 400">US government</span></a><span style="font-weight: 400"> 18F delivery service, the </span><a href="https://api.gouv.fr/"><span style="font-weight: 400">French government</span></a><span style="font-weight: 400">, and the </span><a href="https://apistore.regione.umbria.it/store/"><span style="font-weight: 400">Italian regional government of Umbria</span></a><span style="font-weight: 400">.  </span></p>
<h2><span style="font-weight: 400"><strong>How to add your API to the collaborative catalogue</strong> </span></h2>
<p><span style="font-weight: 400">We’ve outlined the </span><a href="https://github.com/alphagov/api-catalogue/blob/master/TERMS_OF_USE.md"><span style="font-weight: 400">Terms of Use for the API Catalogue</span></a><span style="font-weight: 400"> in the GitHub repository to give a clear understanding of how the API Catalogue will work.</span></p>
<p><span style="font-weight: 400">Adding your API to the catalogue is quick and easy. </span></p>
<ol>
<li style="font-weight: 400"><span style="font-weight: 400">Open a </span><a href="https://github.com/alphagov/api-catalogue/issues"><span style="font-weight: 400">GitHub Issue</span></a><span style="font-weight: 400">.</span><span style="font-weight: 400"> </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">Include a link to your API’s base URL and documentation.</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">Submit the GitHub issue for review.</span></li>
</ol>
<p><span style="font-weight: 400">GDS will review the API Catalogue regularly, respond to Issues and close Issues with APIs that do not follow the Terms of Use. </span></p>
<p><span style="font-weight: 400">The catalogue </span><span style="font-weight: 400">is limited to APIs that exist between government organisations, or between government organisations and industry, or that publish open data. </span></p>
<h2><span style="font-weight: 400"><strong>How you can feedback on this work</strong> </span></h2>
<p><span style="font-weight: 400">We will run a feedback session at one of the next API events to see how departments and local government find contributing to the list. Our next API meetup is in Newcastle and will be hosted by DWP and open to both government employees and suppliers. If you want to attend, you can </span><a href="https://www.eventbrite.co.uk/e/api-community-meet-up-newcastle-tickets-74084931023"><span style="font-weight: 400">sign up on the Eventbrite page</span></a><span style="font-weight: 400">. </span></p>
<p><span style="font-weight: 400">Alternatively you can reach out to us in the comments below or send an </span><a href="mailto:api-standards-request@digital.cabinet-office.gov.uk"><span style="font-weight: 400">email to our Service, Design and Assurance team</span></a><span style="font-weight: 400">. </span></p>
            
            </div>
          </div>
        </article>
      
        <article id="post-4" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 4.  -->
              <a href='https://technology.blog.gov.uk/2019/10/02/improve-csvs-and-api-descriptions-with-these-open-standards-board-recommendations/'>Improve CSVs and API descriptions with these Open Standards Board recommendations</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://technology.blog.gov.uk/category/open-standards/'>Technology in government</a>  &bull;
            </span>
            <span class='item-published'>
              Wednesday October 02, 2019 @ 09:34 &bull;
              4 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p><span style="font-weight: 400"><img class="size-full wp-image-3365 aligncenter" src="https://technology.blog.gov.uk/wp-content/uploads/sites/31/2018/09/open-standards-board-620x436.png" alt="Make things open it makes them better" width="620" height="436" srcset="https://technology.blog.gov.uk/wp-content/uploads/sites/31/2018/09/open-standards-board-620x436.png 620w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2018/09/open-standards-board-620x436-300x211.png 300w, https://technology.blog.gov.uk/wp-content/uploads/sites/31/2018/09/open-standards-board-620x436-435x306.png 435w" sizes="(max-width: 620px) 100vw, 620px" /></span></p>
<p><span style="font-weight: 400">Over the summer, the Open Standards Board received proposals for a standard and specification. Contributors suggested an open standard to make it easier for the government to publish and reuse data, and an open specification to promote the consistent and accurate description of RESTful APIs. </span></p>
<p><span style="font-weight: 400">The Open Standards Board reviewed and approved both proposals and now recommends using the:</span><span style="font-weight: 400"><br />
</span></p>
<ul>
<li style="font-weight: 400"><a href="https://www.gov.uk/government/publications/recommended-open-standards-for-government/tabular-data-standard"><span style="font-weight: 400">RFC 4180 standard to publish tabular data</span></a><span style="font-weight: 400">  </span></li>
<li style="font-weight: 400"><a href="https://www.gov.uk/government/publications/recommended-open-standards-for-government/describing-restful-apis-with-openapi-3"><span style="font-weight: 400">OpenAPI 3 specification for RESTful API descriptions</span></a></li>
</ul>
<h2><b>Why the RFC 4180 standard</b></h2>
<p><span style="font-weight: 400">The comma separated values (CSV) format is a popular way to exchange columns of numbers and text between software. CSV is used for publishing data tables on GOV.UK, often alongside a spreadsheet. The lack of a standard for CSV files can cause problems for people trying to reuse published data. This prompted a </span><a href="https://github.com/alphagov/open-standards/issues/58"><span style="font-weight: 400">challenge on GitHub</span></a><span style="font-weight: 400"> calling for the standardisation of CSV. </span></p>
<p><span style="font-weight: 400">The challenge owner, David Read, Technical Architect at MoJ and contributors worked together to develop a profile of </span><a href="https://tools.ietf.org/html/rfc4180"><span style="font-weight: 400">RFC 4180, an </span><span style="font-weight: 400">Internet Engineering Task Force (</span><span style="font-weight: 400">IETF) specification</span></a><span style="font-weight: 400">, after extensive discussions on the GitHub page.</span></p>
<p><span style="font-weight: 400">The IETF RFC 4180 is a simple document describing a standard format for CSV files. While the RFC leaves some items in the standard as optional, the profile selected by the challenge owner specifies how the standard should be used. For example, character encoding must be UTF-8 and a header row should be included with the data.</span></p>
<p><span style="font-weight: 400">This standard allows the use of CSV files in a wide selection of software tools without editing them first. The consistent formatting makes government open data easier for people to use and saves data analysts’ time.</span></p>
<h2><b>Describing RESTful APIs with OpenAPI 3</b></h2>
<p><span style="font-weight: 400">Another challenge was submitted to use the </span><a href="https://github.com/alphagov/open-standards/issues/31"><span style="font-weight: 400">OpenAPI version 3 to describe RESTful APIs</span></a><span style="font-weight: 400">. </span><span style="font-weight: 400">The proposal was originally raised in 2016 but was deemed as too new, did not have enough supporting tools, and it was not clear if it would be supported by users.</span></p>
<p><span style="font-weight: 400">The Open Standards Board reviewed this challenge again after the specification matured. The board did not mandate the specification as it’s not suitable for all types of APIs but has recommended its use.</span></p>
<p><span style="font-weight: 400">OpenAPI 3 is important because it can help users to:</span></p>
<ul>
<li style="font-weight: 400"><span style="font-weight: 400">generate accurate up to date </span><a href="https://www.gov.uk/guidance/writing-api-reference-documentation"><span style="font-weight: 400">API reference documentation</span></a><span style="font-weight: 400">, no matter what programming language an API is written in</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">validate, version, maintain and update this generated documentation</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">use a consistent API description to help increase adoption of APIs across government by reducing time spent understanding different APIs</span></li>
</ul>
<p><span style="font-weight: 400">Before the Board’s decision to recommend OpenAPI 3, GDS technical writer Jon Glassman carried out further research to confirm: </span><span style="font-weight: 400"><br />
</span></p>
<ul>
<li style="font-weight: 400"><span style="font-weight: 400">OpenAPI 3 was the most common way to describe RESTful APIs</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">the tooling for OpenAPI 3 had continued to develop and evolve </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">the majority of concerns raised previously were no longer valid and people were happy to recommend OpenAPI 3</span></li>
</ul>
<p><span style="font-weight: 400">There are </span><a href="https://openapi.tools/"><span style="font-weight: 400">multiple OpenAPI tools</span></a><span style="font-weight: 400"> available. For example, you can send test requests to your API endpoints using different methods in the interactive API explorer.</span></p>
<p><span style="font-weight: 400">The aim is to encourage API teams to produce definition files in a format that is readable by machines and language-agnostic. No matter what language developers are working in, they will be able to understand the API and what it can do. </span></p>
<p><span style="font-weight: 400">It’s important to remember that this specification only applies to </span><span style="font-weight: 400">describing APIs and generating API reference information. Complete API documentation also covers information like quick start guides and API keys. This is covered by our </span><a href="https://www.gov.uk/government/collections/api-design-guidance"><span style="font-weight: 400">API guidance</span></a><span style="font-weight: 400">.</span></p>
<h2><b>How to propose an open standard</b></h2>
<p><span style="font-weight: 400">If you know of an issue where an open standard for cross-government use will make things better you can submit a proposal.</span></p>
<ol>
<li style="font-weight: 400"><a href="https://github.com/alphagov/open-standards/issues"><span style="font-weight: 400">Visit our GitHub issues page</span></a><span style="font-weight: 400">. </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">Suggest a standard or specification that fits a user need or open a challenge to discover which standards to use in a particular situation. </span></li>
<li style="font-weight: 400"><span style="font-weight: 400">The community will assess and comment on the standard’s openness, applicability and maturity.</span></li>
<li style="font-weight: 400"><span style="font-weight: 400">You will then need to put forward a proposal to the Open Standards Board, which will make the final decision. </span></li>
</ol>
<blockquote class="noquotes"><p>If you’d like to get in touch with any questions about open standards you can drop the team a note on <a href="mailto:openstandards@digital.cabinet-office.gov.uk">openstandards@digital.cabinet-office.gov.uk</a> or leave a comment below.</p></blockquote>
            
            </div>
          </div>
        </article>
      
        <article id="post-5" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 5.  -->
              <a href='https://medium.com/just-tech/bringing-disparate-data-sources-under-control-with-good-metadata-f70c9c57bd13?source=rss----71364e71d6c2---4'>Bringing Disparate Data Sources Under Control with Good Metadata</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Tuesday September 03, 2019 @ 07:38 &bull;
              5 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Robin Linacre, Karik Isichei, George Kelly and Adam Booker (Data Engineering Team)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GOA621efiIAoKecOEOJueQ.jpeg" /><figcaption>Photo by <a href="https://unsplash.com/@srd844?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Stephen Dawson</a> on <a href="https://unsplash.com/search/photos/data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>As a data engineering team, we are responsible for harnessing data and making it simple to use for our analysts. We process data from a plethora of sources, from decades-old database systems through to microservices on our Cloud Platform. Our data needs to be quickly delivered to live webapps, and analysts who use R, Python, and Spark. This variety means we need to find a good tradeoff between consistency and flexibility in data processing.</p><p>The more we work on this problem, the more we understand the importance of tools that standardise our data processing, transforming data sources from arcane, unreliable formats into dependable, reusable commodities.</p><p>Central to this effort is the development of a <a href="https://github.com/moj-analytical-services/metadata_schema">standard for machine readable metadata</a>, and the realisation that once this exists, it is useful in almost every stage of the data pipeline:</p><ul><li>The metadata can serve as specification for data providers, who can easily use our <a href="https://github.com/moj-analytical-services/data_linter">open source library</a> to check conformance of their data against the spec, knowing we will be applying exactly the same checks.</li><li>At data ingestion, we can automate multiple checks of whether the incoming data conforms to the metadata, yielding detailed web reports of rows which failed the checks. See <a href="https://mybinder.org/v2/gh/moj-analytical-services/data_linter_demo/master?filepath=index.ipynb">here</a> for a simple demo.</li><li>During data processing, we can automatically harmonise the wide variety of incoming column data types (string, float, int etc.) from different database systems into a common set.</li><li>We can automatically convert our system-agnostic metadata into the format required by specific data storage solutions, automating the process of setting up databases. This makes it trivial, for instance, to generate the code needed to setup an <a href="https://github.com/moj-analytical-services/etl_manager/blame/master/README.md#L187">AWS Athena Database</a>.</li><li>The metadata can be automatically added to a central, searchable data catalogue, enabling data discoverability. We have developed <a href="https://github.com/moj-analytical-services/metadata_vis">an open source GUI</a> on top of our metadata to enable easy searching and automated SQL query generation.</li><li>Since the metadata for a particular table is just a json file, it can be placed under version control. The metadata is a necessary part of our ETL code, and so it lives in the same repository, meaning metadata stays in sync with the code.</li><li>Finally, authoring metadata is simple and fast. Taking inspiration from the <a href="https://jsonschema.net/">jsonschema generator</a> we can automatically generate a first draft of metadata from existing datasets, and use of our <a href="https://github.com/moj-analytical-services/metadata_schema">metadata schema </a>enables <a href="https://code.visualstudio.com/docs/languages/json#_json-schemas-and-settings">autocompletion</a> of manual edits in text editors like VS Code.</li></ul><p><strong>A simple example</strong></p><p>We have developed an online, interactive demo of some of our tools, which you can find <a href="https://mybinder.org/v2/gh/moj-analytical-services/data_linter_demo/master?filepath=index.ipynb">here</a>. This notebook demonstrates how we can:</p><ul><li>Produce a validation report of a dataset which validates successfully against a metadata schema</li><li>Produce a validation report of a dataset which fails to validate</li><li>Auto-create a draft metadata schema from an existing dataset</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=f70c9c57bd13" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/bringing-disparate-data-sources-under-control-with-good-metadata-f70c9c57bd13">Bringing Disparate Data Sources Under Control with Good Metadata</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-6" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 6.  -->
              <a href='https://medium.com/just-tech/organising-variables-in-terraform-dacbdac5a295?source=rss----71364e71d6c2---4'>Organising Variables in Terraform</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Thursday August 22, 2019 @ 08:51 &bull;
              6 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Andrew Pearce (Web Operations Profession)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ijx4dhkbnW5S-ZLTASVk1w.jpeg" /></figure><p>I use Terraform to provision AWS infrastructure for an application. The app has 3 environments - development, preproduction and production - that have the same configuration.</p><p>Terraform workspaces are used to isolate the resources and to map certain values, such as what AWS account to provision to.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/731/0*x7VTHNT_4S3M3jDl" /></figure><h3><strong>Variable definitions using tfvars</strong></h3><p>Variable definitions let you set values for lots of variables at once. They can read in automatically when you run a terraform apply or terraform plan instead of individually providing them with -var=.</p><p>You can provide values in Terraform’s syntax with terraform.tfvars files, or in JSON format with terraform.tfvars.json.</p><p>terraform.tfvars.json files are how I provide values specific to each environment.</p><p>I’ve been doing this for a while, but I recently found a new way to organise, define and access these values thanks to some improvements in the underlying Terraform language.</p><h3><strong>My old way of organising variables</strong></h3><p>I used to define maps for each variable. Each map held values for dev, preprod and prod:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*uqaePv5qIHMmWNp-" /></figure><p>My tfvars.json had a lot of repeating dev, preprod, prod stanzas:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*WWnoc8ADoN0id2jX" /></figure><p>I would then access my values for each environment using a lookup function, matching the name of the environment:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*hmF6ODORYm46ie_A" /></figure><p>This does have the advantage of being able to supply a default when the lookup fails to return a match.</p><h3><strong>My new way of organising variables</strong></h3><p>Now I am using objects to define many values:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zDiK-aW19ejBvgUO" /></figure><p>Variables can now be organised by environment:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*1-q1mZnBwusxxV9a" /></figure><p>Values can now be accessed from the object using the environment name, which here is available in terraform.workspace:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*mMJ3PaFy6yk0YDCY" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*RMG5rNXDupfDVFDD" /></figure><p>I still have a need for variable maps, and the two can live alongside each other in the terraform.tfvars.json file.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*F1zRlFI6q8jxW-ld" /></figure><h3><strong>Why I prefer this</strong></h3><p>For my purposes, this is much neater and easier to read. All the parameters for each environment are grouped together. Adding another environment would be as easy as copying the block and updating as necessary instead of adding a new line to each variable map.</p><p>I can’t speak to the performance improvements for terraform, but it has made my work faster.</p><p>You can read a full implementation of this <a href="https://github.com/ministryofjustice/opg-lpa/tree/master/terraform/terraform_environment">on GitHub</a>.</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital?source=post_page---------------------------">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/?source=post_page---------------------------">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/?source=post_page---------------------------">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology?source=post_page---------------------------"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=dacbdac5a295" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/organising-variables-in-terraform-dacbdac5a295">Organising Variables in Terraform</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-7" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 7.  -->
              <a href='https://dataingovernment.blog.gov.uk/2019/08/07/when-worlds-collide-putting-data-science-into-production/'>When worlds collide: putting data science into production</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>  &bull;
            </span>
            <span class='item-published'>
              Wednesday August 07, 2019 @ 13:11 &bull;
              6 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p><a href="https://gov.uk/">GOV.UK</a> is the main portal to government for citizens. It enables users to interact with government in a number of situations, from applying for their first driving licence to checking foreign travel advice before jetting off into the sun. With all of the content that’s required to support these tasks, it can be hard for users to find the relevant content they need.</p>
<p>To help users get to the information they need, GOV.UK uses a number of navigational aids – one of them being related links. Related links are shown to the right-hand side of content on a page, linking to other pages which may be of interest.</p>
<p>Currently only around 2% of the entire content on GOV.UK, or 8,000 pages, actually have related links. The rest have no related links at all. This matters because observation and analytics tell us that good related links result in shorter user journeys, enabling users to find the content that they need faster and with ease.</p>
<p><img class="aligncenter wp-image-6984 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/Screen-Shot-2019-06-26-at-20.46.41-620x323.png" alt="A screenshot of a GOV.UK page with related content links highlighted on the right-hand side" width="620" height="323" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/Screen-Shot-2019-06-26-at-20.46.41-620x323.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/Screen-Shot-2019-06-26-at-20.46.41-310x162.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/Screen-Shot-2019-06-26-at-20.46.41-768x401.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/Screen-Shot-2019-06-26-at-20.46.41-435x227.png 435w" sizes="(max-width: 620px) 100vw, 620px" /></p>
<p>So, to improve users’ experience, we investigated whether we could use machine learning on GOV.UK to generate related links for the remaining 98% of content that had none. As a result of this experiment, <a href="https://dataingovernment.blog.gov.uk/2019/06/19/a-or-b-how-we-test-algorithms-on-gov-uk/">we decided to implement the node2vec algorithm</a>.</p>
<h2>The journey to productionising related links</h2>
<p>To productionise, at its simplest, can simply mean to move some algorithm or software into an environment where it’s used to shape the outcome of a process, later consumed by users. When applied to data science, this involves creating a joined-up and automated pipeline from individual steps, such as obtaining input data, running a machine learning algorithm and creating useful output.</p>
<p>Designing such a system for GOV.UK required considering a number of different problem areas to find the best trade-offs for GOV.UK itself, for GDS, and for similar projects within wider government in the future. In this post, you will read about just a few of the considerations we needed to make during the course of the project.</p>
<h2>Hosting and running machine learning</h2>
<p>The first choice we had to make was how we’d host the node2vec machine learning algorithm. Many cloud providers offer what’s called a virtual machine, which – to make an analogy – is simply a computer in the cloud. You can use it to install code libraries, run your machine learning and store the results somewhere. Virtual machines are popular and used widely throughout industry, including to host GOV.UK.</p>
<p>A popular alternative to virtual machines is serverless. Serverless is a model in which you don’t need to worry about how you host your application – meaning the infrastructure on which it runs. Serverless can host everything from fully-fledged websites to ad-hoc, infrequent tasks, alleviating the need for maintenance of the operating system on which it runs.</p>
<p>We chose to use a virtual machine for hosting our machine learning algorithm. Serverless is a popular and exciting technology but our development process for it isn’t fully defined. Virtual machines also act as a stepping stone towards running our applications in containers (think Docker), something that we’re actively looking into at GDS.</p>
<h2>Jupyter notebooks meet Python</h2>
<p>Data scientists at GDS use <a href="https://jupyter.org">Jupyter</a> notebooks for the rapid development and prototyping of solutions to data science problems. In particular, it allows code, documentation and data to live in a single place, which helps to improve both understanding and knowledge sharing between colleagues. From a developer perspective, it’s analogous to an integrated development environment (IDE), like that of Visual Studio or IntelliJ – a tool which makes the process of writing high-quality software easier through various integrations such as offering code optimisations and providing real-time debugging.</p>
<div id="attachment_6982" style="width: 630px" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-6982" class="wp-image-6982 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/190711-Ganesh-Senthi-AI-related-links-blog-post-9923-1-620x414.jpg" alt="Screenshot of a computer screen showing somePython code in a text editor" width="620" height="414" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/190711-Ganesh-Senthi-AI-related-links-blog-post-9923-1-620x414.jpg 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/190711-Ganesh-Senthi-AI-related-links-blog-post-9923-1-310x207.jpg 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/190711-Ganesh-Senthi-AI-related-links-blog-post-9923-1-768x512.jpg 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/190711-Ganesh-Senthi-AI-related-links-blog-post-9923-1-435x290.jpg 435w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/190711-Ganesh-Senthi-AI-related-links-blog-post-9923-1.jpg 1000w" sizes="(max-width: 620px) 100vw, 620px" /><p id="caption-attachment-6982" class="wp-caption-text">Development of the related links Python modules</p></div>
<p>To automate the process of generating related links, we decided to modularise the code from the Jupyter notebooks and write it in object-oriented Python. We borrowed the approach of test-driven development (TDD) from software engineering to focus the development process and ensure functional code.</p>
<h2>Ensuring quality links</h2>
<p>One of our goals was to automate the process of generating related links. To do this, it’s necessary to have confidence in the entire process – both now and in the future. Our related links are based on a combination of how pages on GOV.UK are linked to each other and users’ behaviour on the site over a number of weeks. This means we’ll always be adapting the links we’re generating and the pages we’re generating them for.</p>
<p>In order to ensure a high quality of related links on GOV.UK, we added a number of steps to our process. Firstly, there are a number of pages that we never want to generate related links for or to, which we exclude at both the input and output stages of the link generation process. Next, we apply a confidence threshold to the links generated by node2vec, only allowing through those links that have a good chance of being relevant for a particular page. Finally, we generate a spreadsheet of the top 200 most popular pages, allowing our content designers to critique the related links that have been assigned to these pages and make changes where necessary.</p>
<h2>Rolling back links</h2>
<p>As part of productionising related links, another issue that needed consideration was what should happen if things go wrong, particularly with regards to the links that we suggest to users. This was an important consideration as GOV.UK is the digital face of government, meaning we need to ensure accuracy and relevancy at all times.</p>
<p>With this in mind, we decided to create and store suggested links alongside existing related links for each content item, using a new property in the content schema. This was how we implemented our A/B tests and allowed us to switch between the control and test variants of related links via our content delivery network (CDN). We implemented a similar mechanism (called an <a href="https://martinfowler.com/articles/feature-toggles.html#OpsToggles">operations toggle</a>) via our CDN to show suggested related links. This allows us to switch off these links sitewide, which might be necessary if we detect a batch of bad links has been ingested, or similar.</p>
<p><img class="aligncenter wp-image-6983 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/related_links_team-620x413.jpg" alt="photo of four members of the Related Links team all viewing a computer screen" width="620" height="413" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/related_links_team-620x413.jpg 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/related_links_team-310x207.jpg 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/related_links_team-768x512.jpg 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/related_links_team-435x290.jpg 435w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/08/related_links_team.jpg 2000w" sizes="(max-width: 620px) 100vw, 620px" /></p>
<h2>Generating related links as standard</h2>
<p>Since completing the work to productionise related links, we have been running the process every three weeks and using the links generated to update our content store. Our generated related links are automatically displayed on GOV.UK when publishers haven’t set their own links, ensuring we do as much as possible to help users find the content they’re looking for.</p>
<h2>Next steps</h2>
<p>We’re continuously iterating and refining the related links process, and monitoring results to ensure users’ experiences are improving. In the future, there’s the opportunity that we can bring the model online and use it as part of the publishing process, helping editors creating new content to add relevant related links. All of our code is available to <a href="https://github.com/alphagov/govuk-related-links-recommender">view on GitHub</a>.</p>
<blockquote class="noquotes"><p>If you'd like to know more about how we productionise related links and what we're doing next, please get in touch in the comments below</p></blockquote>
            
            </div>
          </div>
        </article>
      
        <article id="post-8" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 8.  -->
              <a href='https://medium.com/just-tech/how-to-use-multi-stage-docker-builds-a112d1ec8a58?source=rss----71364e71d6c2---4'>How to use multi-stage Docker builds</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Friday July 26, 2019 @ 07:30 &bull;
              7 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Tom Withers (Software Development Profession)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*0kYzCMqZiJ4mYwWR" /><figcaption>Photo by <a href="https://unsplash.com/@guibolduc?utm_source=medium&amp;utm_medium=referral">Guillaume Bolduc</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><p>Docker has revolutionized the way software engineers build applications; small maintainable pieces of software that can be easily scaled to meet demand. But with new technology, there are now more things to take into consideration. One such issue that arose with Docker is image size. Traditionally, to get an efficient docker image, you would use some complex shell commands within the Dockerfile to keep the layers as small as possible.</p><p>In Docker 17.05, multi-stage builds were introduced and this means we can now make docker images even smaller. Below, I’m going to go over an example of how to do this with a Symfony app and composer.</p><p>With multi-stage builds, you can use multiple FROM commands within a single Dockerfile. Each FROM command can use a different base and symbolises a new stage in the build. The most useful thing is that you can selectively copy artefacts from one stage to another leaving everything that you don’t need behind.</p><p>So let’s create a new Dockerfile and add our first FROM command. This will be using composer as a base image, so we can get all of our composer dependencies. We can also name the different stages within the build by adding AS &lt;NAME&gt; to the FROM command.</p><pre>FROM composer AS composer</pre><p>Now let’s copy over our composer.json and composer.lock files. We’re also going to add a RUN command, which will run a composer install.</p><pre>FROM composer AS composer</pre><pre>COPY composer.json /app</pre><pre>COPY composer.lock /app</pre><pre>RUN composer install</pre><p>So the first part of our multi-stage build is done, this will allow us to install our composer dependencies into the first image and then copy them across into the final image.</p><p>Next, we need to build our final stage:</p><pre>FROM php:7-fpm-alpine</pre><pre>WORKDIR /var/www</pre><pre>COPY ./ /app</pre><pre>COPY — from=composer /app/vendor /app/vendor</pre><p>Here, we start a new build using php7-fpm-alpine as the base image, then we use COPY to copy over the vendor folder into our new image. We leave all the composer gubbins behind, and it’s not saved into our final image.</p><p>The full Dockerfile looks like this:</p><pre>FROM composer AS composer</pre><pre>COPY composer.json /app</pre><pre>COPY composer.lock /app</pre><pre>RUN composer install</pre><pre>FROM php:7-fpm-alpine</pre><pre>WORKDIR /var/www</pre><pre>COPY ./ /app</pre><pre>COPY — from=composer /app/vendor /app/vendor</pre><p>You only need a single Dockerfile. Just run docker build and docker the build process will start.</p><p>The end result of using multi-stage builds is a slim production-ready image without any complexity. I hope you can see the benefits of using multi-stage builds and I would definitely encourage you to try them out!</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital?source=post_page---------------------------">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/?source=post_page---------------------------">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/?source=post_page---------------------------">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology?source=post_page---------------------------"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a112d1ec8a58" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/how-to-use-multi-stage-docker-builds-a112d1ec8a58">How to use multi-stage Docker builds</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-9" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 9.  -->
              <a href='https://medium.com/just-tech/working-days-calculator-262e6637377f?source=rss----71364e71d6c2---4'>Working Days Calculator</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Tuesday July 09, 2019 @ 07:31 &bull;
              7 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Rob Nichols (Software Development Profession)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Erpd_TbD76LxPCFU9zVB0g.jpeg" /><figcaption>Photo by <a href="https://unsplash.com/@esteejanssens?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Estée Janssens</a> on <a href="https://unsplash.com/search/photos/calendar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p>Working out how many working days there are between two dates requires not only knowledge of when weekends fall, but also when bank holidays occur. As bank holidays are moved or created to coincide with key national events (Royal Weddings for example), a simple calculation or static data lookup is not a good long term solution.</p><p>In this article, a solution is described that gathers bank holiday data from a GOV-UK API, and uses that data to calculate working day intervals.</p><h3>A Ruby Solution</h3><p>There are a number of gems that will do working day calculations, but to keep them up-to-date they require a list of bank holidays to be passed into them. They make the calculation simpler, but a system to gather bank holiday data is still required.</p><h3>The API</h3><p>There is a <a href="https://www.gov.uk/bank-holidays.json">GOV-UK API</a> that returns up-to-date bank holiday data.</p><h3>Gem selection</h3><p>There were three main gems considered:</p><ul><li><a href="https://github.com/Intrepidd/working_hours"><strong>working_hours</strong></a></li><li><a href="https://github.com/bokmann/business_time"><strong>business_time</strong></a></li><li><a href="https://github.com/gocardless/business"><strong>business</strong></a></li></ul><p>Of these, <em>business_time</em> was last update two years ago. The other two gems both appear to be more regularly maintained. Both <em>business_time</em> and <em>working_hours</em> monkey patch the core Ruby time objects <em>Time</em>, <em>Date</em> and <em>DateTime</em>. As the scope of usage for this project was limited (there was currently only one calculation to be made), using a gem that didn’t monkey patch core objects was a better fit. That left the <em>business</em> gem — and this was selected.</p><h3>Retrieving the data</h3><p>The first task was to create a service that would retrieve the data from the API. The solution was <em>BankHolidayRetriever</em>, which called the API via Net::HTTP.get_response, parsed the resulting JSON and extracted the array of dates from the required section of the data.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/7844a68615efc21f884bbff72e1aa9b6/href">https://medium.com/media/7844a68615efc21f884bbff72e1aa9b6/href</a></iframe><h3>Storing the data</h3><p>The next task was to store the data to locally cache it. After some consideration as to whether to store the data in memory, or in a memcache, it was decided to use the simplest solution of storing the data in the database via an <em>ActiveRecord Model</em>.</p><p>The model was created with a generator:</p><p>rails g model BankHoliday dates:text</p><p>It was then modified to add serialization of dates to store the array coming from BankHolidayRetriever.dates, some simple validation, and a callback that populated dates on creation.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/81aeaa371753c89626ad5acfb2080fa6/href">https://medium.com/media/81aeaa371753c89626ad5acfb2080fa6/href</a></iframe><p>A class method BankHoliday.dates was added that would retrieve the latest updated instance of the model and return its dates, or create an instance if none exists.</p><p>Also added to the dates class method call, was a call out to a worker that would update the current data. In this way the bank holiday data will be updated as it is used.</p><h3>The update worker</h3><p>As <em>Sidekiq</em> was available in the current project, a worker was added that will update the Bank Holiday data. Its first task is to see when the last update occurred. If the last update is less than a certain interval old (currently two days), the worker would just close without doing an update.</p><p>If an update is required, the worker uses a new instance of <em>BankHoliday</em> to gather the latest data. It then compares that data with the latest stored data. If the two match, the “updated at” date of the last persisted <em>BankHoliday</em> instance is updated (via touch).</p><p>If the latest stored data does not match the retrieved data, then the new instance is saved and it becomes the latest stored data in the database.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/f0f34a61efc0550490f3adf85b7929ef/href">https://medium.com/media/f0f34a61efc0550490f3adf85b7929ef/href</a></iframe><p>Note that failure to retrieve the data or save it to the database, raises an exception. When this happens within a worker, this will cause the worker to be put into the retry queue for it to be run again later. In this way short term API and or data errors can be handled without adding additional code.</p><h3>The Calculator</h3><p>With the system now able to return an up-to-date array of bank holiday dates, it was a straightforward task to create a working day calculator using the <em>business</em> gem.</p><p>As this gem accepts the dates as strings, there was no need to convert them to dates first, which simplifies the code.</p><p>At the time of writing all that was required was a way of returning a date a number of days ahead of today. As the <em>business</em> gem provides a number of working day calculations, it will be fairly simple to extend the functionality as required.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/38d26e72793a67b616b95a529d816b5a/href">https://medium.com/media/38d26e72793a67b616b95a529d816b5a/href</a></iframe><h3>The end result</h3><p>With these changes in place, within the app the date ten working days from now can be returned with the call :</p><p>WorkingDayCalculator.working_days_from_now(10)</p><p>Making that call will trigger a worker that will check that the data is up-to-date for the next call.</p><p>The complete set of code with specs, within the context it was used can be seen in the <a href="https://github.com/ministryofjustice/laa-apply-for-legal-aid/pull/593">Pull Request</a>.</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=262e6637377f" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/working-days-calculator-262e6637377f">Working Days Calculator</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-10" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 10.  -->
              <a href='https://dataingovernment.blog.gov.uk/2019/06/19/a-or-b-how-we-test-algorithms-on-gov-uk/'>A or B? How we test algorithms on GOV.UK</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>  &bull;
            </span>
            <span class='item-published'>
              Wednesday June 19, 2019 @ 16:37 &bull;
              8 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>GOV.UK is home to guidance, news and information from all government departments. We have over 400,000 unique pieces of content, and to give our users the best experience, we need to get them to the most useful content as quickly as possible.</p>
<p>One way of doing this is by adding links to the ‘related content’ section on the right-hand side of each page, so that users can easily navigate to similar pages.</p>
<p><img class="aligncenter wp-image-6958 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image4-e1560961786520-620x380.png" alt="Image showing the UK bank holiday page on GOV.UK, with a right side panel showing two related content links, namely “Holiday entitlement” and “School term and holiday dates”" width="620" height="380" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image4-e1560961786520-620x380.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image4-e1560961786520-310x190.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image4-e1560961786520-768x470.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image4-e1560961786520-435x266.png 435w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image4-e1560961786520.png 1999w" sizes="(max-width: 620px) 100vw, 620px" /></p>
<h2>Creating related links</h2>
<p>Historically, related links were hand-curated by content publishers with expert domain knowledge. Around 2,000 pages on GOV.UK have these links and to extend this feature to all pages would take a long time. This is where data science can help.</p>
<p>A variety of methods have been documented to have worked well in industry for this task; we needed to test these on our specific use case. We used machine learning algorithms based on our previous work on <a href="https://dataingovernment.blog.gov.uk/2019/05/23/detecting-semantic-similarity-on-gov-uk/">semantic similarity</a> and <a href="https://dataingovernment.blog.gov.uk/2019/05/29/connecting-the-dots-network-science-on-gov-uk/">network science</a> (log likelihood ratio and Node2Vec) to generate these links automatically.</p>
<h2>What would success look like?</h2>
<p>We use the <a href="https://en.wikipedia.org/wiki/Scientific_method">scientific method</a> to empirically evaluate any changes we make to the site. We formulate hypotheses and test their falsehood using evidence. We organised workshop sessions with a diverse team of <a href="http://gov.uk">GOV.UK</a> experts to decide on testable hypotheses.</p>
<p><img class="aligncenter wp-image-6955 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/Data-1-620x413.png" alt="Image showing three people in a workshop, with post-its on the window." width="620" height="413" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/Data-1-620x413.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/Data-1-310x207.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/Data-1-768x512.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/Data-1-435x290.png 435w" sizes="(max-width: 620px) 100vw, 620px" /></p>
<p>We explored the data available to us to see what we could measure during the test. We presented the options back to our team, explaining how they would be calculated and their feasibility. As a team, we discussed which metrics were expected to change if the newly-generated links were any good. We narrowed it down to a handful of metrics that could be framed as <a href="https://www.ucl.ac.uk/child-health/short-courses-events/about-statistical-courses/research-methods-and-statistics/chapter-6-content-4">null hypotheses</a>.</p>
<h2>A/B testing our hypotheses</h2>
<p>Two of the null hypotheses we tested were:</p>
<ol>
<li>There is no significant difference in the proportion of journeys using at least one related link. If this is true, then people aren’t clicking our links, probably because they don’t find them useful or interesting.</li>
<li>There is no significant difference in the proportion of journeys that use internal search. If this is true, then we didn’t provide people with relevant links to click on so they still use internal search to navigate.</li>
</ol>
<p>To test these, we ran a randomised experiment and assigned users via a digital coin toss to one of 2 possible versions of the site with equal probability: half the users were directed to the control site (A) and the other half to the site with the algorithmically generated related links (B). This is known as an <a href="https://en.wikipedia.org/wiki/A/B_testing">A/B test</a> and is a popular way of testing changes to digital products.</p>
<div id="attachment_6959" style="width: 630px" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-6959" class="wp-image-6959 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image3-620x434.png" alt="Image showing the A and B variant versions of the “Paternity pay and leave” page on GOV.UK. The A variant on the left is the control page without any related links, and the B variant on the right has 5 related content items that were generated by algorithms" width="620" height="434" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image3-620x434.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image3-310x217.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image3-768x537.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image3-435x304.png 435w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/image3.png 1662w" sizes="(max-width: 620px) 100vw, 620px" /><p id="caption-attachment-6959" class="wp-caption-text">An example of an A and B variant page, on the left and right, respectively</p></div>
<p>We wanted to bring our false negative rate down below 20%, so we estimated a good sample size for each experiment; each algorithm’s related links would need to be live for about a week. This meant that we had a very short window between analysing the results, iterating algorithms to make improvements and generating the new and improved related links. So to speed up our approach we wrote <a href="https://github.com/ukgovdatascience/govuk_ab_analysis">code as a software package on Github</a> that enabled us to run the analysis instantly upon experiment completion.</p>
<p>This initial early investment into automation reduced the risk of human error and freed up our time to implement other algorithms. Any of our data scientists could run the analysis and get consistent results to present back to the team, and each experiment was analysed in exactly the same way.</p>
<h2>Statistical significance vs practical significance</h2>
<p>Excitingly, both of our null hypotheses were shown to be false, meaning that something very interesting was happening on the site.</p>
<p>Our first hypothesis being false implies that users found the related links interesting and/or relevant so they clicked them. For our best-scoring algorithms, users were clicking our related links for over 2.4% of their journeys – that’s improved journeys for more than 10,000 users per day!</p>
<p>But more interestingly, our second hypothesis being false means that users don’t appear as lost on the site as they don’t use internal search as much. The results show that there’s a potential reduction in internal search by about 20 to 40% depending on the algorithm used.</p>
<p><img class="aligncenter wp-image-6956 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/rap_blog_ab-620x372.png" alt="Figure showing the reduction in journeys using internal search for the 3 algorithms tested. Results are: 20% for content similarity, 25% for node2vec and 35% for log likelihood ratio. All scores have error bars of about ±5%" width="620" height="372" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/rap_blog_ab-620x372.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/rap_blog_ab-310x186.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/rap_blog_ab-768x461.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/rap_blog_ab-435x261.png 435w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/rap_blog_ab.png 1500w" sizes="(max-width: 620px) 100vw, 620px" /></p>
<p>These scores were not the only considerations for selecting our winning algorithm to deploy – we also considered the economic, social, political and technological ramifications of each approach. Out of the 2 top-scoring algorithms, we decided to implement Node2Vec as it has more potential for improvement.</p>
<p>Moreover, we decided that we would not replace the hand-curated links in those 2,000 pages that had them, as despite how good our algorithms are at the moment, they still do not have the same context as a subject matter expert.</p>
<p>Prior to this work, the vast majority of GOV.UK pages did not have curated recommended links. We automated that process, improving thousands of user journeys per day.</p>
<p>We are very excited to put our algorithmically-generated related links in production within the GOV.UK infrastructure and we’ll tell you how this went soon!</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-11" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 11.  -->
              <a href='https://dataingovernment.blog.gov.uk/2019/06/14/natural-language-processing-in-government/'>Natural Language Processing in government</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>  &bull;
            </span>
            <span class='item-published'>
              Friday June 14, 2019 @ 10:32 &bull;
              8 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>The <a href="https://gds.blog.gov.uk/2017/07/20/building-capability-and-community-through-the-government-data-science-partnership/">Government Data Science Partnership</a> (GDSP) brings together public servants to share knowledge about data science. It’s a collaboration between the Government Digital Service (GDS), Office for National Statistics (ONS) and the Government Office for Science.</p>
<p>At our latest meet-up about 60 people, from more than 20 departments and public bodies, gathered in Manchester to discuss Natural Language Processing (NLP).</p>
<p>NLP is used to interpret unstructured text data, such as free-text notes or survey feedback. It can help us look for similarities and uncover patterns in what people have written, which is a difficult task because of nuances in sentence structure and meaning.</p>
<div id="attachment_6928" style="width: 630px" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-6928" class="wp-image-6928 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190613_part-of-speech-620x243.png" alt="The sentence 'the cat sat on the map' with parts of speech tagging highlighted - the (article) cat (noun) sat (verb) on (preposition) the (article) mat (noun)" width="620" height="243" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190613_part-of-speech-620x243.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190613_part-of-speech-310x121.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190613_part-of-speech-768x300.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190613_part-of-speech-435x170.png 435w" sizes="(max-width: 620px) 100vw, 620px" /><p id="caption-attachment-6928" class="wp-caption-text">Labelling a sentence with parts of speech, such as nouns (‘cat’ and ‘mat’) and verbs (‘sat’), to help understand syntax.</p></div>
<p>We’ve written before about NLP for <a href="https://dataingovernment.blog.gov.uk/2016/12/20/using-machine-learning-to-classify-user-comments-on-gov-uk/">classifying user feedback</a> and <a href="https://dataingovernment.blog.gov.uk/2017/01/12/using-data-science-to-build-a-taxonomy-for-gov-uk/">tagging pages of GOV.UK</a>, and the Ministry of Justice have used it to <a href="https://mojdigital.blog.gov.uk/2017/12/20/using-textual-analysis-to-build-better-services/">identify document relationships</a>. At the meet-up we heard from data scientists across the public sector on how NLP is being used in their organisations.</p>
<h1>Finding patterns</h1>
<p>Computers can do a better job than humans at identifying patterns in text datasets. On the day, 2 data scientists spoke about their use of unsupervised machine learning to help them. This is when a computer is used to find patterns in the data without any prior information about what it should be looking for.</p>
<p>Dan Schofield from NHS Digital was tasked with identifying meaningful groupings from the free-text input of a nationwide dataset of appointments in GP practices. He used Python to convert his documents to numbers with <a href="https://radimrehurek.com/gensim/models/doc2vec.html">Doc2Vec</a> and simplified their complexity using <a href="https://lvdmaaten.github.io/tsne/">an approach called t-SNE (t-Distributed Stochastic Neighbourhood Embedding)</a>. Dan fed this information into an <a href="https://hdbscan.readthedocs.io/en/latest/index.html">algorithm called HDBSCAN</a> to find meaningful groups, including one that contained appointments related to injections.</p>
<p>Luke Stanbra from the Department for Work and Pensions presented on using free-text data to group incident support tickets and find common root causes. Like Dan, Luke used an unsupervised approach called topic modelling to solve this problem. He discussed <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation</a> (LDA) to assign texts to abstract ‘topics’ that represent word distributions and how <a href="https://www.structuraltopicmodel.com/">structural topic models</a> can improve models by taking into account document-level data.</p>
<h1>Creating pipelines</h1>
<p>As well as unsupervised machine learning, supervised techniques are also used for NLP. This is when an algorithm predicts a label for new data based on some data that’s already been labelled by humans with specialist knowledge.</p>
<p>Ben Stanbury, Neil Potter and their team at HM Revenue and Customs (HMRC) used both supervised and unsupervised techniques in a pipeline to help classify and present thousands of feedback items that are received each day by the department.</p>
<p>HMRC staff tagged a sample of comments, and the team used this to train a supervised classification model, making use of <a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support Vector Machines</a> and <a href="https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab">Gradient Boosting Machines</a>. The model tagged incoming data when its confidence in a label was high enough. Unlabelled comments were passed into an unsupervised LDA topic model to identify emerging topics that could become new tags, ensuring data wasn’t wasted.</p>
<div id="attachment_6930" style="width: 630px" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-6930" class="wp-image-6930 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190508_hmrc-workflow-620x489.png" alt="Diagram showing the flow of comments in the HMRC system. New comments flow into the supervised model, unclassified comments are clustered in an unsupervised model before being sent back to HMRC staff" width="620" height="489" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190508_hmrc-workflow-620x489.png 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190508_hmrc-workflow-310x244.png 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190508_hmrc-workflow-768x606.png 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/06/20190508_hmrc-workflow-435x343.png 435w" sizes="(max-width: 620px) 100vw, 620px" /><p id="caption-attachment-6930" class="wp-caption-text">A supervised model classifies new comments after training on manually tagged ones. Any leftover unclassified comments are grouped for review by an unsupervised model</p></div>
<h1>Summarising text</h1>
<p>NLP is not always about grouping and labelling data based on free-text content. Data science approaches can also be used to help summarise documents.</p>
<p>This can be a tricky and time-consuming job for a human, so <a href="https://datasciencecampus.ons.gov.uk/author/chaitanya-joshi/">Chaitanya Joshi</a> from the <a href="https://datasciencecampus.ons.gov.uk/">ONS Data Science Campus</a> has explored ways to speed up and automate this process with a method called extractive text summarisation.</p>
<p>During his investigations, he used an unsupervised machine learning method called <a href="https://arxiv.org/abs/1506.06726">skip-thoughts</a> to cluster similar sentences and select the most representative ones for each cluster. The method is based on a word-level skip-gram approach but extended to sentences. It results in a small number of sentences that best represent the whole document.</p>
<h1>Peer surgery</h1>
<p>After hearing the talks, attendees split into groups to ask questions and get solutions from the community about how to prepare data for NLP and use machine learning to make sense of it.</p>
<p>One topic discussed was a fundamental problem with text data: misspellings. For example, ‘Monday’ and ‘Mondya’ will not be recorded as the same word. Suggested solutions included the use of dictionary lookups and word-clustering algorithms.</p>
<p>Another group discussed <a href="https://datasciencecampus.ons.gov.uk/o-p-t-i-m-u-s-turning-free-text-lists-into-hierarchical-datasets/">an open source tool from the Data Science Campus called Optimus</a>. Optimus takes short text records and helps to group and label them automatically.</p>
<p>The session closed with participants feeding back on what they’d learnt from the discussions and how they can go back to their organisations with this knowledge in mind.</p>
<h1>Get involved</h1>
<blockquote class="noquotes"><p>Public servants can continue the NLP conversation in <a href="https://govdatascience.slack.com/messages/C0NF51LE4/">the #nlp channel</a> on the <a href="https://govdatascience.slack.com/">cross-government data science Slack</a>. You can also register your interest for upcoming text analytics meet-ups by <a href="mailto:textanalyticscoi@homeoffice.gov.uk">emailing the organisers</a>.</p>
<p>GDSP meet-ups are open to anyone in government with an interest in data science techniques. <a href="https://blog.us15.list-manage.com/subscribe?u=fe5d4a0d2b6e6ba6201b54e01&amp;id=d7630ed182">Sign up for the mailing list </a>or join <a href="https://govdatascience.slack.com/messages/C1LJKK292/">the #community_of_interest channel</a> on Slack. The next GDSP meeting will be in London on Thursday 27 June.</p></blockquote>
            
            </div>
          </div>
        </article>
      
        <article id="post-12" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 12.  -->
              <a href='https://medium.com/just-tech/reducing-cost-and-latency-of-change-for-legacy-services-5ab85a0f339f?source=rss----71364e71d6c2---4'>Reducing cost and latency of change for legacy services</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Monday June 17, 2019 @ 11:26 &bull;
              8 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by <a href="https://twitter.com/jabley">James Abley</a> (Technical Architecture Profession)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Xkyr-y0AgzwgqzJIZ2LKDA.jpeg" /></figure><h3>Context</h3><p>Like a lot of parts of government, the <a href="https://www.gov.uk/government/organisations/ministry-of-justice">Ministry of Justice</a> has a large technology estate. Ours includes many things which pre-date <a href="https://www.gov.uk/guidance/digital-and-technology-spend-controls-version-5">GDS spend controls</a>. <a href="https://www.gov.uk/guidance/g-cloud-buyers-guide">How government bought things</a> has <a href="https://www.digitalmarketplace.service.gov.uk/">changed over the last 6 years</a>. But we still have things from before that time. In this article, I’m <a href="https://blog.usejournal.com/toxic-technology-the-growing-legacy-threat-b95ad098a339">calling those things legacy services</a>.</p><p>Many of these legacy services are business-critical core systems without which we could not operate. It would cause massive amounts of pain/frustration if they weren’t available. Our <a href="https://twitter.com/daverog">CTO Dave Rogers</a> has <a href="https://medium.com/@daverog/deep-transformation-a745167befcf">written about some of the problems faced when trying to transform these ageing services</a>.</p><p>Delivering substantive changes to services can take time. But just because something is hard doesn’t mean it’s not worth doing. And if you do it right, you can end up in a much better place, making continuous small improvements.</p><h3>Our problems</h3><p>Some of the properties of these systems are less than desirable. For example, changes are very infrequent. We have services that are only updated once per year. These changes are risky affairs. Downtime with weekend work is the norm. Then there is usually the unofficially accepted post-release cleanup period. This involves further unplanned releases to address problems introduced by the planned release.</p><p>Infrequent releases are not great for the people using the system who may be experiencing frustration. Batching up fixes in this way means we are delaying improving people’s quality of life. That’s quite a blunt way of putting it; it’s meant to be.</p><p>So the cost of change is too large. Changing the services involved the work of many people over a long period of time.</p><p><a href="https://www.amazon.co.uk/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">The book Accelerate</a> by <a href="https://twitter.com/nicolefv">Dr Nicole Forsgren</a>, <a href="https://twitter.com/jezhumble">Jez Humble</a>, and <a href="https://twitter.com/realgenekim">Gene Kim</a> contains a wealth of evidence (science FTW!) about high-performing technology organisations. It talks about 4 key metrics that are useful to measure when trying to understand Software Delivery Performance:</p><ol><li><strong>Lead time</strong> — the time it takes from a customer making a request to the request being fulfilled</li><li><strong>Deployment Frequency</strong> — this is a proxy for batch size, which is easier to measure and typically has low variability</li><li><strong>Mean Time to Restore (MTTR)</strong> — when a service incident occurs, how quickly is service restored?</li><li><strong>Change Fail Percentage</strong> — what percentage of changes to production fail?</li></ol><p>If we’re doing one release a year, we can see that the average lead time is 6 months. Deployment frequency is annual. The mean time to restore was a week, but sometimes fixes were expedited and done mid-week rather than waiting for another weekend to do a release.</p><p>And the Change Fail Percentage was very high. Maybe not quite 100%, but not far off.</p><h3>Our journey</h3><p>We recently migrated all the services for the Legal Aid Agency from traditional hosting. A business case had established that moving some of the services to the public cloud would give us financial benefits.</p><p>But we also managed to eke out some other benefits as part of the migration. We have made huge improvements to the metrics mentioned above.</p><p>We had some guiding principles for the migration to public cloud:</p><ol><li>We will move out of the current data centre</li><li>We will not provide the service in a way that is any worse than the current service</li><li>Applications delivered into public cloud will have a stable, automated deployment pipeline</li><li>Applications in public cloud should capable of redeployment during normal working hours</li></ol><p>These were enough to get the organisation (and our users!) to a much better place:</p><ul><li>We have got the lead time to the same day, for small changes/fixes.</li><li>The deployment frequency averaged around every 3 days* (previously it was once a year).</li><li>Mean Time To Restore is currently untested, but the lead time and deployment frequency numbers show that it would be resolved on the same day.</li><li>Change Fail Percentage has dropped to 0%.</li></ul><h3>How we did this</h3><h4>Deployment pipeline</h4><p>A deployment pipeline is an automated manifestation of your process for getting changes into an environment. Adopting a deployment pipeline means that <a href="https://twitter.com/jabley/status/1005045771593494528">all changes have to go through version-control</a>. A change happens in version-control and that starts a build. This enhancement to the system in how people worked ensured visibility of changes.</p><p>The application/service gets built once and then deployed everywhere with the relevant configuration for that environment. This gave a nice separation between things that tend to have different rates of change — the application code, and the configuration for each environment.</p><h4>Trunk-based development</h4><p><a href="https://trunkbaseddevelopment.com">Trunk-based development</a> has helped:</p><ul><li>ensure small batch sizes</li><li>increase the frequency of deployments</li><li>reduce the risk of deployments</li><li>reduce the time spent merging long-lived branches.</li></ul><p>And we can try to break down work so that useful increments can be delivered regularly.</p><p>Stabilisation periods are no longer necessary. Time spent doing difficult merges of long-lived branches that have diverged a long way from the main trunk branch is no longer needed.</p><h4>Adding automated tests</h4><p>Many of the legacy services were created when Test-Driven Development and other practices were not as widespread. They do not have a vast suite of automated tests with a high level of coverage which give us the confidence to know we aren’t breaking things.</p><p>The most valuable investment we decided we could make was adding functional tests which exercised the way our users would typically use the applications. If we could replicate the happy path of how people used the system, we could manage the risk that:</p><ol><li>The migration would not break anything</li><li>We could continue to improve and fix things post-migration</li></ol><p>These sorts of tests are slower to execute, since they typically need a few distributed components, but they gave us the best level of coverage when working with code bases that had not been designed to be testable.</p><p>As part of the deployment pipeline, these tests are a quality gate that runs for every potential change which might go in front of our users.</p><h3>Eliminating waste</h3><p>From <a href="https://www.amazon.co.uk/Lean-Software-Development-Agile-Toolkit/dp/0321150783">a Lean sense</a>, we have also <a href="https://en.wikipedia.org/wiki/Lean_software_development#Eliminate_waste">eliminated various wasteful activities</a>.</p><p>When we had long-lived branches, we used to have a different environment per-branch. People had to track which version was in which environment.</p><p>Now that we’re doing trunk-based development with the ability to deploy to production on the same day, we don’t need to do that. If someone asks what version is in environment X, we always know:</p><ol><li>The deployment pipeline keeps track of it now, rather than a person, so check what the deployment pipeline says is deployed in environment X</li><li>But mostly the answer will be “trunk”</li></ol><p>We have also got rid of several environments; we no longer need to pay for them, or manage them, due to our new ways of working.</p><h3>Conclusion</h3><p>We started the migration wanting to realise the cost-savings available to us from using public cloud. In truth, we know we are still very early on in the journey for this part of the organisation. And it’s not evenly distributed. Some of our colleagues have to work with bits that are still harder than they should be to change and improve.</p><p>But we have achieved lots of small improvements. Small batch sizes:</p><ul><li>reduce risk</li><li>give opportunity for faster feedback and learning opportunities</li><li>are faster to deliver value to the organisation and our users</li></ul><p>That is such a massive difference for the organisation, and something we should be immensely proud of.</p><p>*It was quite high for a while because, for the first time, we had better insight about how the systems were running in production. We could access the logs and see the graphs. We could see the unreported frustrations that our users were tolerating or working around every day. So we fixed them. For most of the teams now, it’s a capability that they can choose to exercise as part of their normal sprint cadence (typically fortnightly).</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5ab85a0f339f" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/reducing-cost-and-latency-of-change-for-legacy-services-5ab85a0f339f">Reducing cost and latency of change for legacy services</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-13" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 13.  -->
              <a href='https://medium.com/just-tech/automated-unit-testing-of-pl-sql-1d9d6f77a960?source=rss----71364e71d6c2---4'>Automated Unit Testing of PL/SQL</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Monday June 10, 2019 @ 13:30 &bull;
              8 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Laurence Barea (Software Development Profession)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*oLzYVS6985vnFNm0mMJC7w.jpeg" /></figure><p>As we moved to the adoption of CI/CD during our infrastructure and application migration to AWS, there was always a question mark surrounding Oracle and PL/SQL releases; we did not have the tools or frameworks available to allow us to deploy Oracle releases via a pipeline, which is not ideal given our goals for deployment automation are concerned.</p><p><a href="https://www.thoughtworks.com/insights/blog/why-test-automation-backbone-continuous-delivery">Testing is backbone of continuous delivery model.</a></p><p>The problem we are having is that although many programming languages out there lend themselves to this process, Oracle databases and its procedural language, PL/SQL, does not.</p><p>Currently, there is a large Oracle footprint within the estate and a correspondingly significant amount of PL/SQL code that sits outside the CI/CD pipeline resulting in Oracle releases having to be deployed manually by DBA’s. This is an issue; delays are created, the release process is made more complex and the involvement of other teams are required.</p><h3>Testing database deployment</h3><p>We considered <a href="https://flywaydb.org/">Flyway by Boxfuse</a> and <a href="https://www.liquibase.org/">Liquibase by Datical.</a> We decided on Liquibase and have been generally pleased with the approach it takes and how it fits in to our workflow. Flyway looked promising but would have cost $3,000 to support our version of Oracle.</p><h3>Testing PL/SQL</h3><p>With regards to PL/SQL we have set up a proof of concept to see a couple of possible solutions in action. Initially, we considered these tools:</p><ul><li>Oracle’s SQL Developer’s built in unit testing</li><li>Code Tester by Quest (Toad)</li><li>utPLSQL, a framework that’s been around for a few years which was originally developed by <a href="https://www.stevenfeuerstein.com/">Steve Feuerstein</a> himself, and</li><li>ruby-plsql-spec, a unit testing framework which is built using Ruby, ruby-plsql (library) and Rspec.</li></ul><p>… and decided on <a href="http://utplsql.org/">utPLSQL</a> and <a href="https://github.com/rsim/ruby-plsql-spec">ruby-plsql-spec</a>. The former because it was more well-established and the latter because of the growing Ruby competency among our teams.</p><h3>The Ruby way</h3><p>The conclusion is ruby-plsql-spec works great! See the <a href="https://docs.google.com/presentation/d/e/2PACX-1vQAed94rI3vk6Sc8zd2h1-nqGBZyhroO38OlgNJBPJit4pUOzbPRwXRypdup3eq-0KzwokTdXH2R79X/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p">Unit Testing PL/SQL Procedures From Ruby Code</a> for a more in-depth look.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*i9h13kQzmlYSaJFs1PjleQ.png" /><figcaption>See slides here: <a href="https://docs.google.com/presentation/d/e/2PACX-1vQAed94rI3vk6Sc8zd2h1-nqGBZyhroO38OlgNJBPJit4pUOzbPRwXRypdup3eq-0KzwokTdXH2R79X/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p">Unit Testing PL/SQL Procedures From Ruby Code</a></figcaption></figure><h3>The utPLSQL way</h3><p>We deployed utPLSQL onto a development database. Unfortunately we can’t run the database locally at the moment 😞 so we share a single development database hosted in Amazon — there’s a separate piece of work going on to resolve this.</p><p>The initial challenges surrounded taking the automated install apart and doing it manually — this is because AWS RDS does not allow file-system access and it was something we could get on with straight away rather than getting the install scripts to run remotely from the DB in question.</p><p>Working with utPLSQL is very much a manual process; there is no automation — you will have to write all the test code and you will have to maintain it.</p><p>Below is some output generated utPLSQL tests run on the HUB development environment.</p><pre>Between string function</pre><pre>Returns substring from start position to end position [.129 sec] (FAILED - 1)</pre><pre>Returns substring when start position is zero [.002 sec] (FAILED - 2)</pre><pre>Failures:</pre><pre>1) basic_usage</pre><pre>Actual: &#39;234&#39; (varchar2) was expected to equal: &#39;2345&#39; (varchar2 at &quot;HUB.TEST_BETWNSTR&quot;, line 5 ut.expect(betwnstr(&#39;1234567&#39;, 2, 5)).to_equal(&#39;2345&#39;);</pre><pre>2) zero_start_position</pre><pre>Actual: &#39;1234&#39; (varchar2) was expected to equal: &#39;12345&#39; (varchar2 at &quot;HUB.TEST_BETWNSTR&quot;, line 10 ut.expect(betwnstr( &#39;1234567&#39;, 0, 5 ) ).to_equal(&#39;12345&#39;);</pre><pre>Finished in .131936 seconds</pre><pre>2 tests, 2 failed, 0 errored, 0 disabled, 0 warning(s)</pre><h3>Next steps</h3><p>Now that we have got both these frameworks working, we need to start incorporating them into actual work so that we can better understand how best to benefit from them.</p><p>A few points we will be looking to address as we go forwards:</p><ul><li>Testing across multiple databases</li><li>Standing up and tearing down databases as part of the automated testing</li><li>Transaction testing e.g. table data, rollbacks to savepoints etc.</li><li>Complex type testing e.g. associative arrays of nested objects</li><li>Integration with the code pipeline and Flyway DB.</li><li>Exception handling.</li><li>TDD going forwards with regards to the existing code-base.</li></ul><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1d9d6f77a960" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/automated-unit-testing-of-pl-sql-1d9d6f77a960">Automated Unit Testing of PL/SQL</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-14" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 14.  -->
              <a href='https://medium.com/just-tech/measuring-against-cyber-security-standards-82082c9031a7?source=rss----71364e71d6c2---4'>Measuring against cyber security standards</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Thursday June 06, 2019 @ 11:44 &bull;
              8 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>By <a href="https://twitter.com/@JoelGSamuel">Joel Samuel</a> (Cyber Security Consultant Team)</p><p><em>MoJ’s Cyber Security team is led by </em><a href="https://twitter.com/JonPLawrence"><em>Jonathan Lawrence</em></a><em>, Chief Information Security Officer, and is responsible for helping the whole department manage cyber security risks through expert advice/ guidance, incident management/ response and proactive ‘offensive’ penetration testing.</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dW9pMZ7kw0Qa8gU7PiS2kg.jpeg" /></figure><h3>Measuring security is hard</h3><p>The relatively simple concept of being sure you have the right security in place to keep systems (and the data within) safe (also known as ‘information assurance’) is easier said than done.</p><p>There are various methodologies for determining risk, measuring controls, value of controls (and so on) and each require a varying level of expertise by the assessor in order to complete them. One size definitely does not fit all when the team is responsible for cyber security in systems ranging from internal IT tools/solutions (laptops, WiFi, Google G-Suite, Microsoft Office 365, Trello, Slack and so on) to case management solutions used for administering over £1 billion a year in legal aid, as well as brand new digital services.</p><h3>External standards</h3><p>There are various external standards that a UK central government organisation is expected to adhere to. One of the key ones for cyber security is the <a href="https://www.gov.uk/government/publications/the-minimum-cyber-security-standard">Minimum Cyber Security Standard</a> (MCSS) that was developed by the <a href="https://www.gov.uk/government/organisations/cabinet-office">Cabinet Office</a> in collaboration with the <a href="https://www.ncsc.gov.uk/">National Cyber Security Centre</a> (NCSC).</p><h3>The Challenge</h3><p>I posed the problem of how in an imperfect cyber security or ‘information assurance’ world does the team measure a diverse range of technology solutions against the MCSS while also making the assessment method simple to use, repeatable, standardised and in a format that would allow us to compare different systems using the same measurements to identify trends horizontally… a tall ask!</p><h3>Design with data</h3><p>The 3rd <a href="https://www.gov.uk/guidance/government-design-principles">government design principle</a> is “<a href="https://www.gov.uk/guidance/government-design-principles#design-with-data">design with data</a>” and, while this is a different kind of ‘design’, I thought this principle matched the challenge really well so I decided to ensure any method created <em>data</em> that could be dynamically turn into <em>information</em>. Free-text is hard to read, analyse and update and is subject to variations in terminology and intention.</p><p><a href="https://twitter.com/warmana">Adrian</a> has <a href="https://medium.com/just-tech/data-or-information-is-there-a-difference-and-does-it-matter-355bb9f4a408">posted about this before</a>.</p><h3>Et voila! Welcome to Standards Assurance Tables</h3><p>I used a bit of math (often quite basic!), <a href="https://support.google.com/docs/answer/3093340?hl=en&amp;ref_topic=9199554">IMPORTRANGE()</a> and a smidge of Google Script to create a template Google Sheet spreadsheet and dubbed it the <strong>Standards Assurance Table</strong>.</p><p>The MOJ believes ‘security’ can work in the open so in addition to publishing it’s <a href="https://github.com/ministryofjustice/itpolicycontent/">IT policies</a>, as part of an open-sourced <a href="https://ministryofjustice.github.io/security-guidance/">cyber security guidance microsite</a>, <strong>the MOJ have published </strong><a href="https://ministryofjustice.github.io/security-guidance/guides/standards-assurance-tables/#standards-assurance-tables"><strong>how the Standard Assurance Tables work and the theory behind them</strong></a>.</p><p>Some information risk management concepts were maintained such as maintaining the use of ‘evidence’ (documentation, drawings and so on — not hearsay) and ‘confidence’ (how well the assessor thinks the evidence demonstrates the target system is meeting the standard) but ultimately ignored existing information risk methodologies for the purposes of this work, to create a clean, simple slate.</p><h3>A horizontal view</h3><p>At the same time an aggregator Google Sheet was created for collated analysis. The aggregator uses even more IMPORTRANGE() to pull all completed Standards Assurance Tables together for horizontal analysis and this works really well given data was kept as data.</p><p>As a result of this work the MOJ has already identified trends (across entirely diverse systems that have never before been compared) and this has directly led how the team are investing time and money to get the most amount of proportional security benefit while responsibly managing public funds.</p><h3>Designed for scale</h3><p>The table wasn’t named the “MCSS Table” because while this work began due to a particular standard I wanted to ensure any method can scale and adapt over time.</p><p>The team are now working with information governance colleagues across the MOJ to expand the <a href="https://ministryofjustice.github.io/security-guidance/guides/standards-assurance-tables/#objectives">objectives</a> beyond the MCSS and build some really powerful data-driven governance and investment.</p><h3>Onwards</h3><p>At the moment the <a href="https://ministryofjustice.github.io/security-guidance/guides/standards-assurance-tables/#standards-assurance-tables">Standards Assurance Tables</a> nor the aggregating Google Sheet analyse or represent change over time to keep the initial scope reasonable.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/79ec4344dd81ea761f65b1190f1ac36b/href">https://medium.com/media/79ec4344dd81ea761f65b1190f1ac36b/href</a></iframe><p>Each table already has an active Google Script that records changes as they are made. One of the things the team want to do next is leverage this metadata to help measure how systems fair over time, individually and in aggregate — which I think will be quite nifty.</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=82082c9031a7" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/measuring-against-cyber-security-standards-82082c9031a7">Measuring against cyber security standards</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-15" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 15.  -->
              <a href='https://medium.com/just-tech/when-making-a-private-github-repository-public-audit-the-pull-requests-154200d02f7f?source=rss----71364e71d6c2---4'>When making a private GitHub repository public, audit the pull requests</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://medium.com/just-tech'>Just Tech</a>  &bull;
            </span>
            <span class='item-published'>
              Friday May 31, 2019 @ 15:04 &bull;
              9 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <p>by Mat Moore (Software Development Profession)</p><p>The GOV.UK Service Manual encourages us to <a href="https://www.gov.uk/service-manual/technology/making-source-code-open-and-reusable">make source code open source</a>. This is a great policy because it <a href="https://mojdigital.blog.gov.uk/2017/02/21/why-we-code-in-the-open/">holds us to account and allows code to be reused by other teams</a>. It’s also common for software-as-a-service solutions that work with GitHub to charge extra for private repositories, so open source makes it cheaper and easier for us to deliver software.</p><p>If you make your code open from the start of the project, it’s easy to do it securely. But what about making existing source code open? <a href="https://technology.blog.gov.uk/2018/02/19/how-to-open-up-closed-code/">How to open up closed code</a> by Anna Shipman explores 3 approaches for managing this:</p><ul><li>Cycle all the credentials</li><li>Rewrite the git history to remove sensitive information</li><li>Move the code to a new repository bit by bit</li></ul><p>When my team decided to make one of our private repositories public, we decided to go with option 2 — Rewrite the git history to remove sensitive information — because it would be easier for us than rotating credentials. It turned out this was not enough to avoid disclosing credentials because of the way GitHub references diffs in pull requests.</p><p><a href="https://help.github.com/en/articles/removing-sensitive-data-from-a-repository">GitHub’s own advice</a> states that:</p><blockquote>Once you have pushed a commit to GitHub, you should consider any data it contains to be compromised.</blockquote><h3>What went wrong</h3><p>When the project was originally created, we’d mostly avoided committing credentials to the repository. Instead, we used AWS Parameter Store to manage configuration and credentials for each environment — these get passed into the application as environment variables.</p><p>Unfortunately, the repository did contain one credential. We depend on a shared development database, and we’d committed a password for this in the docker-compose.yml file, which is used to run the application locally.</p><p>To address this we ran <a href="https://help.github.com/en/articles/removing-sensitive-data-from-a-repository">git filter-branch</a> to completely remove the file from the git history.</p><p>We then recreated our docker compose configuration using a separate docker-compose.override.yml file, which is encrypted with <a href="https://github.com/AGWA/git-crypt">git-crypt</a>.</p><p>Unfortunately, the first pull request for this didn’t set up git-crypt correctly, and when reviewing it, I added a comment to point this out. What I didn’t realise is that this comment would persist even after the commit had been rebased and the branch deleted. Whenever code is commented on, GitHub retains the diff and just adds an “outdated” badge if the code is no longer in the repository.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-YsYhUByLbGRPRjhPn0SaA.png" /></figure><p>This ultimately caused us to leak the credential when we made the repository public. Luckily, we noticed this shortly after and changed the credential.</p><h3>How to avoid this</h3><p>Many automated tools for detecting secrets focus on the git repository itself, rather than the project page on GitHub.</p><p>The problem is that any comment ever made in a code review could potentially expose secrets. In our case the repository was fairly new, so we could have manually audited GitHub issues and pull requests to check for anything sensitive, but this might not always be feasible.</p><p>You could avoid this problem by choosing either of the other two approaches Anna describes in her blog post:</p><ul><li>cycling all the credentials</li><li>starting a new repository entirely.</li></ul><p>You could also combine rewriting history with moving to a fresh repository. This way, you preserve your code’s history, but you get rid of existing issues and pull requests. This means you lose some of the context around the code, but you only need to sanitise the git repository itself before making the repository public.</p><p>If you enjoyed this article, please feel free to hit the👏 clap button and leave a response below. You also can <a href="https://twitter.com/Justice_Digital">follow us on Twitter</a>, read our <a href="https://mojdigital.blog.gov.uk/">other blog</a> or check us out on <a href="https://www.linkedin.com/company/uk-ministry-of-justice/">LinkedIn</a>.</p><p><strong>If you’d like to come and work with us, please check current vacancies on our </strong><a href="https://jobs.jobvite.com/justicedigitalandtechnology"><strong>job board</strong></a><strong>!</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=154200d02f7f" width="1" height="1"><hr><p><a href="https://medium.com/just-tech/when-making-a-private-github-repository-public-audit-the-pull-requests-154200d02f7f">When making a private GitHub repository public, audit the pull requests</a> was originally published in <a href="https://medium.com/just-tech">Just Tech</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
            
            </div>
          </div>
        </article>
      
        <article id="post-16" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 16.  -->
              <a href='https://dataingovernment.blog.gov.uk/2019/05/29/connecting-the-dots-network-science-on-gov-uk/'>Connecting the dots: network science on GOV.UK</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>  &bull;
            </span>
            <span class='item-published'>
              Wednesday May 29, 2019 @ 14:00 &bull;
              9 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <h2><img class="aligncenter wp-image-6880 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/19-05-22-Nicky-Zachariou-data-blog-post-9901-620x413.jpg" alt="Image showing 3 post-its describing the 3 network types: (a) structural, (b) functional and (3) semantic. The respective ways of inducing a relationship between the pages in the networks are: (a) hyperlink exists from one page to go to the next, (b) user clicks to go from one page to the next and (c) the documents are semantically similar" width="620" height="413" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/19-05-22-Nicky-Zachariou-data-blog-post-9901-620x413.jpg 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/19-05-22-Nicky-Zachariou-data-blog-post-9901-310x207.jpg 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/19-05-22-Nicky-Zachariou-data-blog-post-9901-768x512.jpg 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/19-05-22-Nicky-Zachariou-data-blog-post-9901-435x290.jpg 435w" sizes="(max-width: 620px) 100vw, 620px" /></h2>
<h2>GOV.UK can be represented as a multilayer network</h2>
<p>GOV.UK is a group of pages that comprises the best place to find government services and information. In its most abstract form, GOV.UK can be represented as a network made of pages, represented as nodes, that are connected to each other using links.</p>
<p>The links indicate a relationship between the pages, and the way we define them can give us different insights about our content.</p>
<p>Currently, we have three ways we can connect pages: via the hardcoded links found in the text, by users clicking from one page to visit another and, finally, by their <a href="https://dataingovernment.blog.gov.uk/2019/05/23/detecting-semantic-similarity-on-gov-uk/">semantic similarity</a>.</p>
<h2>Publishers define the structural network</h2>
<p>When publishers create a new piece of content they include links to other related pages. Then certain navigational links that facilitate browsing, like breadcrumbs and other items from the <a href="https://dataingovernment.blog.gov.uk/2018/10/19/how-we-used-deep-learning-to-structure-gov-uks-content/">relevant topic in the taxonomy</a>, are automatically linked to the new content item. In this way, the structural network of GOV.UK is created, consisting of approximately 250,000 nodes and 350,000 links.</p>
<p>When we first started using network science methods on the site, our aim was to assess its structural integrity and connectivity. We wanted to know whether all content areas of the site are accessible and linked to – which turns out they are, but a few are more remote than others.</p>
<p>We also wanted to identify the pages that are much more connected than others – what we now call hubs. To investigate these, we calculated network properties, including network density, connectedness, link distribution and centrality measures.</p>
<p>Network analysis has also proven useful in evaluating individual pages. While there are a few ways to describe the format and aboutness of a page, it’s more difficult to determine its position and significance within the overall network. For critical content, we have ranked pages by the number of different functional connections they facilitate, their node neighbourhoods and the subnetworks and communities they belong to.</p>
<h2>Users create the functional network</h2>
<p>The functional network of GOV.UK is induced by users clicking from one page to visit another, using any of the available links or by using internal search. We create single user journeys by chaining together user page hits within a session and then we accumulate these to create the functional network.</p>
<div id="attachment_6903" style="width: 630px" class="wp-caption aligncenter"><img aria-describedby="caption-attachment-6903" class="wp-image-6903 size-large" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/networkpath-620x521.jpg" alt="Image showing an example of a functional network path, represented as a series of GOV.UK pages clicked in order by a user traversing along hyperlinks." width="620" height="521" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/networkpath-620x521.jpg 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/networkpath-310x261.jpg 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/networkpath-768x646.jpg 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/networkpath-435x366.jpg 435w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/networkpath.jpg 1782w" sizes="(max-width: 620px) 100vw, 620px" /><p id="caption-attachment-6903" class="wp-caption-text">Figure showing the functional network path created from a user traversing along hyperlinks.</p></div>
<p>&nbsp;</p>
<p>We did a bit of data engineering and created a Python tool (<a href="https://github.com/alphagov/govuk-network-data">GOV.UK Network Data Pipeline</a>) to automatically extract user journeys from BigQuery – the database that stores our Google Analytics data. These were then aggregated over a specific time period to produce the resulting functional network.</p>
<p>Our main motivation for using this functional network is to learn from how users interact with the site.</p>
<h2>Understanding how users navigate the site</h2>
<p>One of the things we learned is that despite there being a lot of content on GOV.UK, it turns out users tend to visit a relatively small part of the site. Around 2% of pages are visited at least once in 87% of user journeys.</p>
<p>Also, visits to service pages are very frequent and important. Over a third of journeys contain a service page, and their resulting subnetworks are very densely connected. For example, there are about 250 different links that lead to the<i> ‘</i><a href="https://www.gov.uk/sign-in-universal-credit">Sign in to your Universal Credit account</a>’ page.</p>
<p>And on an average day, between 10 and 15% of the traffic on the site is unique. That means that we have about 1 million unique user journeys, indicating that users go about finding their information in differing ways.</p>
<h2>Improving findability using multilayer temporal networks</h2>
<p>We wanted to improve the user experience by helping users find the information they seek in fewer steps. So we compared the functional network to the underlying structural network, and used this to inform structural changes that would improve navigation.</p>
<p>For example, where the users were not taking the structural shortest paths, we introduced a <a href="https://gds.blog.gov.uk/2018/10/17/building-a-better-gov-uk-step-by-step/">step by step</a> process, enforcing a sequence of pages that would be visited in order. And where it wasn’t necessary for users to get information from multiple pages, we added shortcuts to what we thought were their destination pages. Keep your eyes peeled for future blog posts showing how we created these shortcuts and  evaluated them using A/B testing.</p>
<p>The authors would like to acknowledge Dr Paul Expert (Imperial College London) for his advice on using network science to improve findability on GOV.UK.</p>
<p>This work will be presented at <a href="https://twitter.com/2019netsci">NetSci 2019</a>, the flagship conference of the Network Science Society, that aims to bring together leading network science researchers and practitioners.</p>
<blockquote class="noquotes"><p>If you want to play with GOV.UK networks yourself, then we have uploaded a copy of the <a href="https://data.gov.uk/dataset/00f43927-0c93-4f9e-9632-b082fdbb0299/gov-uk-structural-network-adjacency-list">structural network</a> to give you a head start!</p></blockquote>
            
            </div>
          </div>
        </article>
      
        <article id="post-17" class='item'>
          <header class='item-header'>
            <h2>
              <!-- 17.  -->
              <a href='https://dataingovernment.blog.gov.uk/2019/05/23/detecting-semantic-similarity-on-gov-uk/'>Detecting semantic similarity on GOV.UK</a>
            </h2>

            <span class='item-feed-title'>
            <a href='https://dataingovernment.blog.gov.uk/category/data-science/machine-learning/'>Data in government</a>  &bull;
            </span>
            <span class='item-published'>
              Thursday May 23, 2019 @ 13:49 &bull;
              9 months ago
            </span>
          </header>

          <div class='item-body'>
            <div class='item-content item-summary'>
            <!--
              note: content goes first; than try summary
            -->
            
              <h2>Representing text as vectors</h2>
<p>We can represent the text on each GOV.UK page as a semantic <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs">vector</a>. This is denoted by a list of numbers, which conveys information about the page contents.</p>
<p><a href="https://github.com/alphagov/content-similarity-models">We tried</a> a few ways to develop these semantic vectors, like <a href="https://radimrehurek.com/gensim/models/doc2vec.html">Gensim’s Doc2vec</a>, fine-tuning the <a href="https://github.com/google-research/bert">BERT pre-trained base model</a> and Google’s <a href="https://tfhub.dev/google/universal-sentence-encoder/2">universal sentence encoder</a>.</p>
<p>The latter uses a deep averaging network (DAN) encoder trained on text from a variety of sources. It <a href="https://arxiv.org/pdf/1803.11175.pdf">outperforms</a> Doc2vec in the <a href="http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark">STS benchmark</a> and was quick to implement, so we selected it for use in solving GOV.UK problems.</p>
<div>
<div><img class="size-large wp-image-6871 aligncenter" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/19-05-22-Nicky-Zachariou-data-blog-post-9915-620x413.jpg" alt="Two post-its showing cosine distance for similar pages (small angle) and non-similar pages (wide angle)" width="620" height="413" /></div>
</div>
<p>Each semantic vector represents a content item and the cosine of the angle between the vectors is called ‘the cosine distance’. The smaller the angle, the more similar the items are, and vice versa.</p>
<h2>Measuring vector similarity</h2>
<p>The position of semantic vectors in the vector space tells us about their meaning. Neighbouring vectors represent pages that are similar to each other, and distant ones denote pages that are different.</p>
<p>We can measure how similar 2 items of content are to each other by using the angle created by their respective vectors. The similarity score is called ‘the cosine distance’, and is calculated by taking the cosine of the angle between the two vectors.</p>
<p>As expected, content items which are more similar will have a smaller angle between them and thus a larger similarity score, and vice versa.</p>
<h2>Identifying duplicate content with vector similarity</h2>
<p>Over the last 6 months, 700 content items have been published on GOV.UK per week. This high publishing rate can result in multiple content items being published to serve the same user need. This is unnecessary and confusing for users.</p>
<p>Semantic similarity can identify duplicate content, and can inform publishers where their content overlaps with pre-existing content. This can be done at the publication stage – to prevent duplicate content arising – as well as retrospectively – to clean up existing duplicate content.</p>
<h2>Informing decisions about the topic taxonomy</h2>
<p>One important characteristic for our content is the taxon is organised in the topic taxonomy. The taxonomy is currently structured like a tree with each topic representing the aboutness of the content tagged to it.</p>
<p>We are still iterating both the structure and tagging approach for the topic taxonomy, and there are various ways that the semantic vectors can be used to inform decisions about changing the taxonomy.</p>
<p>We can identify problem branches in the topic taxonomy by calculating the average cosine distance across all pairs of content in a taxon, and use this as a metric for taxon diversity. Knowing how diverse the content is helps us to diagnose taxons which are too broad and identify possible clusters of content (for example, using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html">DBSCAN</a>) that warrant their own taxon.</p>
<p><img class="size-large wp-image-6874 aligncenter" src="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/similarity-tsne-620x482.jpg" alt="An X-Y scatter graph where the dots represent different pages. Two clusters (similar content) are highlighted - department spends over £25k and gender pay gap" width="620" height="482" srcset="https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/similarity-tsne-620x482.jpg 620w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/similarity-tsne-310x241.jpg 310w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/similarity-tsne-768x597.jpg 768w, https://dataingovernment.blog.gov.uk/wp-content/uploads/sites/46/2019/05/similarity-tsne-435x338.jpg 435w" sizes="(max-width: 620px) 100vw, 620px" /></p>
<p>A 2D <a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">t-SNE representation</a> of the semantic vectors of all content in the corporate information taxon of the topic taxonomy. Some distinct clusters of content exist that could potentially form new lower-level taxons.</p>
<h3>Optimising search and navigation</h3>
<p>There are various ways in which we can improve our site search and navigation, if our content were better organised and tagged with appropriate metadata. One approach we have been exploring is the use of automatically generated related links, displayed on the right-hand side of GOV.UK pages, to help people get to and explore the content they need.</p>
<p>Our first experiment to generate these links used the semantic vector representation of content to display the most semantically similar pages to each page.</p>
<p>But more on this soon!</p>
<blockquote class="noquotes"><p><a href="https://dataingovernment.blog.gov.uk/subscribe/">Subscribe to this blog.</a></p></blockquote>
            
            </div>
          </div>
        </article>
      <!-- each item -->
      </main>
    </div><!-- container -->
  </body>
</html>
